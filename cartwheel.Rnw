%% LyX 2.2.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[twoside,english,3p]{elsarticle}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\pagestyle{headings}
\usepackage{xcolor}
\usepackage{calc}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{graphicx}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecolor{lyxadded}{rgb}{0,0,1}
\providecolor{lyxdeleted}{rgb}{1,0,0}
%% Change tracking with ulem
\DeclareRobustCommand{\lyxadded}[3]{{\color{lyxadded}{}#3}}
\DeclareRobustCommand{\lyxdeleted}[3]{{\color{lyxdeleted}\sout{#3}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newcommand{\code}[1]{\texttt{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% specify here the journal
\journal{Energy and Buildings}

% use this if you need line numbers
\usepackage{lineno}

\usepackage{hyperref}
\usepackage{url}

\makeatother

\usepackage{babel}
\begin{document}

\begin{frontmatter}{}

\title{Bayesian evaluation of energy conservation measures: a case study
with a model-predictive controller for space heating on a commercial
building}


\author[nb]{David~Lindelöf\corref{cor1}}

\ead{david.lindelof@neurobat.net}

\author[nb]{Mohammad~Alisafaee}

\author[nb]{Pierluca~Borsò}

\author[nb]{Christian~Grigis}

\author[nb]{Jean~Viaene}

\author[nb]{Xavier~Mocellin}

\cortext[cor1]{Corresponding author}

\address[nb]{Neurobat AG, Rue de Veyrot 9, 1217 Meyrin, +41 22 552.11.62}
\begin{abstract}
Retrofitting existing buildings to improve their energy efficiency
is an investment that most building owners do eventually consider.
Faced with a variety of options, ranging from trivial (replacing light
bulbs) to major projects (better façade insulation), an owner will
want to know which energy conservation measure is likely to yield
the highest return on investment\textemdash and with what confidence.
Moreover, once the measure has been applied, the owner will want to
know how well it performs and whether their money was well spent\textemdash also
known as Measurement \& Verification.

But conventional M\&V mandates the establishment of a pre-measure
baseline, normally requiring the instrumentation of the building during
a year or more, driving the costs of M\&V to sometimes unacceptable
levels. Furthermore, a typical M\&V study will report a single number
for the measure's efficiency, ignoring (and failing to report) any
uncertainty surrounding that estimate.

To solve these two problems (expensive establishment of a baseline
and absence of uncertainty in the reported efficiency), we have developed
a method, based on Bayesian statistics, that will 1) rely on historic
utility bills and climate data to establish a baseline, and 2) estimate
the post-retrofit energy savings and report them together with suitable
confidence intervals.

We have applied this method after installing, in March 2016, a commercial
model-predictive controller for space heating for a medium-sized office
building in Switzerland. The baseline was established from historic
oil tank refill records. 55 days after installing the controller,
the energy efficiency improvement of the building was assessed and
found to have improved by 26.8\%, with 18.4 percentage points standard
error. 
\end{abstract}
\begin{keyword}
Bayesian inference \sep heating degree-days\sep base temperature\sep
balance point temperature\sep total heat loss coefficient\sep heating
base load
\end{keyword}

\end{frontmatter}{}

<<setup, include=FALSE>>=
library(homeR)

library(ggplot2)
library(lubridate)
library(plyr)
library(reshape2)
library(zoo)

theme_set(theme_bw())

opts_chunk$set(error = FALSE, warning = FALSE, echo = FALSE,
               dev = "tikz", dev.args = list(pointsize = 10),
               fig.width = 3.5, fig.height = 3.5, fig.align = "center")

source("inference3.R")
nice <- function(x, n = 1) format(round(x, digits = n), nsmall = n)
@

\section{Introduction}

Many energy conservation measures (ECM) exist to reduce the consumption
of energy in existing buildings, but vary widely in effectiveness.
Faced with a variety of options, ranging from trivial (replacing light
bulbs) to major projects (better façade insulation), an owner will
want to know which energy conservation measure is likely to yield
the highest return on investment\textemdash and with what confidence.
Moreover, once the measure has been applied, the owner will want to
know how well it performs and whether their money was well spent\textemdash also
known as Measurement \& Verification. But conventional M\&V mandates
the establishment of a pre-measure baseline, normally requiring the
instrumentation of the building during a year or more, driving the
costs of M\&V to sometimes unacceptable levels. Furthermore, a typical
M\&V study will report a single number for the measure's efficiency,
ignoring (and failing to report) any uncertainty surrounding that
estimate.

This is a recurring problem for large companies in Switzerland that
have publicly committed themselves to reducing their greenhouse gas
emissions. The majority of these emissions can be traced to large
portfolios of legacy buildings, in particular to the fossil fuels
used for heating. Reducing the heating energy for legacy buildings
(while maintaining user comfort) will help such companies achieve
their objectives\textemdash provided those energy savings can be proven.
Given a choice between ECMs, a facility manager will frequently favor
those perceived as being of relatively low-risk, even when their effectiveness
might be less attractive.

There is no widely-accepted method to select an ECM for a particular
project, and a lack of confidence in their effectiveness limits their
adoption \citep{Ma2012}. As a discipline, we must show building owners
that assessing the effectiveness of ECMs is not a research project
anymore but a well-stream

\subsection{The need to quantify uncertainties when assessing the effectiveness
of ECM}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\citet{Ma2012} note that confidence in the effectiveness of energy
conservation measures limit their adoption. Trust in computer simulations
can only go so far, and more experience with practical case studies
are needed. Evaluating the effectiveness of an ECM cannot remain a
research project forever; the whole process needs to be streamlined.%
\end{minipage}}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
The issue of risk is frequently ignored or overlooked. Here we consider
two kinds of risks: 1) the risk that the ECM might not be as effective
as advertised, and 2) the risk that, although effective, the benefits
will turn out to be difficult to prove.%
\end{minipage}}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
Improving the heating system's controller (such as by replacing it
with a model-predictive controller) belongs to the ECM category of
``Energy efficient equipment and low energy technologies'', a form
of demand side management \citep{Ma2012}.%
\end{minipage}}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
Some M\&V projects are easier than others; when there is no factors
that need adjustment for, for example. Replacing light bulbs in commercial
buildings is one such example, where M\&V can be done without bothering
about any adjustment. \citep{Lee2000}%
\end{minipage}}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\citep{Xia2013}An attempt to provide a rigorous footing to M\&V,
so it escapes its image of an \textquotedbl{}an inaccurate science:
an engineering practice relying heavily on professional judge- ment\textquotedbl{}

Attempt to formulate optimal M\&V plan.

No attempt to formulate uncertainty in savings estimates.%
\end{minipage}}

\subsection{The IPMVP on uncertainties}

The International Protocol for TK is the gold standard of M\&V processes. 

\subsection{Recent assessments}

A Scopus search for the ``IPMVP'' term in a document's title, abstract
or keywords, limited to publication date from 2010 to present, yields
37 documents. Of these, just 3 study the energy efficiency of an ECM
without resorting to computer simulation. They were:
\begin{itemize}
\item \citet{Aris2015}: retrofit of a water cooling package unit. Baseline
consumption July 2012 to June 2013 modeled as linear combination of
occupancy, number of working days and cooling degree-days. Calculates
energy avoided from August 2013 to July 2014. t-test finds no statistically
significant energy savings.
\item \citep{Ginestet2010} applies the IPMVP to an existing building equipped
with a new HVAC device. The energy savings are determined by 1) simulation
and 2) by retrofitting one room and leaving another one unchanged.
\item \citep{Kaiser2010} reports on the results from a large-scale program
where 730 households participated, and 150 are chosen at random. Baseline
established as linear model in HDD, CDD, relative humidity and energy
price. No uncertainties are reported.
\end{itemize}
Other retrofir assessments found in the literature include:
\begin{itemize}
\item \citep{Cohen1991}old but relevant: 32 retrofit projects, ranging
in size from three to 30 000 houses. Energy normalised by HDD using
fixed 65 F. Mix of submetered, utility bills.
\item \citep{Lin2015}Electricity and gas bill for a 31'000m2 campus whose
HVAC equipment was retrofitted. IMPVP option C. Baseline from Sept
2007 to August 2008. Measurement from May 2009 to April 2010. Normalised
to outdoor temperature. Savings reported without uncertainty.
\end{itemize}
\citep{Walter2014}Models electric load as function of time of week
and outdoor temperature. Nonlinear dependency on outdoor temperature.

Cross-validation used to quantify uncertainty in baseline estimation.

Having access to full-year of data does not necessarily improve baseline
estimates.

17 buildings analysed. Half have 27 months of data, other half 12.

Method is a good indicator for predicting baseline error for a single
month (the last one), but uncertainties highly variable from building
to building.

Notes that when using the energy avoided (need to check the term)
method, the uncertainty is entirely due to the uncertainty in the
baseline.

When uncertainty in baseline higher than expected savings, no savings
can be proved.

\section{Bayesian formalism}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
``Bayesian inference is the process of fitting a probability model
to a set of data and summarizing the result by a probability distribution
on the parameters of the model and on unobserved quantities such as
predictions for new observations'' (BDA3)%
\end{minipage}}

\section{Experimental building}

The Sargans building shown in Fig. 1 includes four heating circuits,
covering 1234 m2, with heating water provided by an oil-fired boiler.
The NOLa system was installed in March 2016 on three of the four circuits,
generally referred to as Neubau, Büro, and Wohnung, the latter two
belonging to the old part of the building (Altbau). The fourth circuit
was deemed not to require optimisation, as the zone in question is
kept relatively cool.

The oil-fired boiler draws its fuel from two tanks and provides the
heating water to all heating circuits. The levels in the tanks are
recorded at irregular intervals, such as when either (or both) tank
was refilled. The domestic hot water is provided by an independent
circuit.

Neurobat\textquoteright s adaptive model-predictive control algorithm
regularly calculates an optimal value for the temperature of the water
prepared by the oil boiler. This value cannot be communicated directly
to most legacy heating controllers; instead, the NOLa system controls
the flow temperature indirectly by modulating the outdoor temperature
measured by the heating controllers. Thus, the boiler provides for
each circuit a heating water at just the right temperature.

The sensors attached to the NOLa system (including an oil meter) are
automatically sampled several times per hour and stored in a database.
The data is used for monitoring in near real time, and for offline
data analysis.

\begin{figure}
\includegraphics[width=0.8\columnwidth]{img/sargans_composite}

\caption{Aerial (top left) and side views of the Altbau (bottom) and Neubau
(right) parts of the Sargans building. The Büro and Wohnung circuits
belong to the Altbau part.}

\end{figure}


\section{Bayesian energy model}

The energy consumed by a building is rarely constant but varies over
time due to so-called routine factors (expected to vary, such as the
climate) and non-routine factors (normally constant, such as the function
of the building). These factors must be accounted for when assessing
the effectiveness of an ECM. This is normally done by establishing
a model for the energy use before and after the installation of the
ECM, as we do here.

Under normal conditions, the daily heating demand of a building will
balance the building's heat loss. The daily losses $Q_{d}$ can be
taken as proportional to the positive difference between the average
outdoor temperature and the building's \emph{base temperature}: $Q_{d}=K\times(t_{\text{b}}-\overline{t_{\text{out}}}_{d})^{+}$
where the base temperature $t_{\text{b}}$ of a building is defined
as the outdoor temperature above which all heat losses are compensated
by the sun and other free gains. $K$ is the building's \emph{total
heat loss coefficient}, the quantity of extra heat required per day
to maintain indoor comfort for each extra degree of cold. It is the
most important metric when assessing the efficacy of a new heating
control algorithm.

Over a period $p$ of several days, the total heating load will be
\[
Q_{p}=\sum_{d\in p}Q_{d}=K\times DD_{p}
\]
where $DD_{p}=\sum_{d\in p}(t_{\text{b}}-\overline{t_{\text{out}}}_{d})^{+}$
is the number of \emph{degree-days at base temperature $t_{\text{b}}$}
during that period. $Q_{p}$ is frequently available as utility bills
or energy meter readouts, while $DD_{p}$ must be calculated from
historic weather data.

Installing an ECM such as the NOL\textsuperscript{a} will alter the
building's total heat loss coefficient by a factor $\rho$, and also
possibly shift the base temperature if the indoor setpoints are not
exactly identical before and after the installation: 
\[
K_{\mathrm{pre}}\rightarrow K_{\mathrm{post}}=\rho\times K_{\mathrm{pre}}
\]
\[
t_{\text{b},\text{pre}}\rightarrow t_{\text{b},\mathrm{post}}=\Delta t_{\text{b}}+t_{\text{b},\mathrm{pre}}
\]
Our task is to estimate the heat loss coefficients before and after
the installation, and their ratio $\rho$. The lower $\rho$ is, the
higher the energy savings. The relative energy savings in percent
will be given by $100\times(1-\rho)$.

The analysis of the historic weather and oil consumption data will
be explained in the following sections, followed by the analysis of
the new consumption data. 

\section{Historic weather and oil consumption data}

The International Performance Measurement and Verification Protocol
(IPMVP) requires an auditor to establish the performance of the building
before the installation of the ECM (the \emph{baseline} period) and
after (the \emph{reporting} period). Unlike traditional IPMVP projects,
this pilot building is challenging because daily oil consumption readouts
were available only after the installation of the NOL\textsuperscript{a}.
The energy savings must therefore be derived from heterogenous sources
of data: manual oil level readouts before the installation, and automated
daily oil readouts after. Traditional analysis methods have trouble
dealing with such situations, especially for estimating a building's
base temperature from historic utility bills. We have developed a
method based on Bayesian statistical methods, that can deal with such
data and derive the heat loss coefficient before and after the installation.
The details are out of scope of this report, but the full method is
described in a paper submitted for publication in an upcoming issue
of Energy \& Buildings, and recently accepted pending minor revisions.
The algorithm has been implemented as the \code{bhm()} function in
Neurobat's \code{homeR} R package, freely available from CRAN \citep{homeR}
.

\subsection{Weather data}

The historic weather data (going back to 2011) is obtained from {[}MeteoSuisse{]}(http://www.meteosuisse.admin.ch/home.html),
who provides a file with average daily temperatures measured in Bad
Ragaz (about 6 km from Sargans) and Vaduz (about 10 km). The relative
positions of the pilot building in Sargans and of the Bad Ragaz and
Vaduz weather stations are shown in Fig. \textbackslash{}ref\{fig:stations\}
in the Appendix. The data from the stations is shown against time
in Fig. \textbackslash{}ref\{fig:PlotClimate\}. A scatterplot of the
temperatures from Bad Ragaz against those from Vaduz is shown in Fig.
\textbackslash{}ref\{fig:ScatterPlotClimate\}. There are no obvious
differences between the two weather stations. From here onwards, we
use the data from Bad Ragaz. 

<<>>=
climate2 <- read.table("data/RAD_VAD.txt",
  skip = 10,
  na.strings = "32767",
  colClasses = c(V1 = "factor"))
climate2 <- transform(climate2, Date = as.Date(ymd(paste(V2, V3, V4, sep = "-"))))
climate2 <- subset(climate2, select = c(1, 8, 7))
names(climate2) <- c("Station", "Date", "Temperature")
levels(climate2$Station) <- c("Bad Ragaz", "Vaduz")
climate <- climate2
climate.wide <- dcast(climate, Date ~ Station) 
@

<<PlotClimate, fig.cap="Historic outdoor temperature measured at nearby weather stations. There is no obvious disagreement between the stations.", fig.width=5, fig.height=3>>=
ggplot(climate, aes(Date, Temperature, color = Station)) +
	geom_line() +
	xlim(as.Date("2010-12-20"), as.Date("2016-04-30")) +
	theme(legend.position="top")
@

<<ClimateScatterPlot, fig.cap="Comparison of Bad Ragaz and Vaduz temperatures.", fig.width=4>>=
ggplot(climate.wide, aes(`Bad Ragaz`, Vaduz)) + geom_point(size = 1) + coord_fixed() 
@

\subsection{Baseline oil consumption}

The historic oil consumption data consists in a sheet of paper used
to log the readouts of the oil levels in the boiler's tanks. A copy
of the original paper is shown in Fig. \textbackslash{}ref\{fig:readouts\}
in the Appendix. We import it in a form suitable for data analysis.

<<>>=
oilReadingsDf <- read.table(text = "
Date        Tank1  Tank2
2011-02-03   7500  13300
2011-05-25   5500  13000
2011-10-25   4000  13000
2011-11-25  10700     NA
2012-02-23  10500   3300
2012-04-10  10000    500
2012-05-02     NA  11100
2012-05-27   8000  10500
2013-01-15  10000  10300
2013-03-06  10000   5200
2013-06-17  10000   5000
2013-08-15   9500      0
2013-08-15  13450  12500
2013-11-27  13437   8800
2014-07-25   9500    500
2014-09-24   9000    500
2014-09-24   9000  12500
2014-11-18   7000  12500
2014-11-18   9100  12500
2014-12-03   7400  12500
2015-02-10     NA  12400
2015-03-25      0   7500
2015-06-10  13200  10000
2015-12-15  13200   3500
2016-03-08   8500     NA
",
                          header = TRUE,
                          colClasses = c(Date = "Date"))
oilReadings <- zoo(oilReadingsDf[,-1], order.by = oilReadingsDf$Date)
oilReadings <- transform(oilReadings, Total = Tank1 + Tank2)
oilReadings
@

There are log entries (for example 2012-05-02) when one tank was filled
without recording its level before the refill. In such instances it
is impossible to know how much oil was used during the preceding period.
We therefore restrict this data to the 12 periods \emph{during which
neither tank level increased}.

Each period is matched with its historic weather data, yielding a
list of mean daily outdoor temperatures for each day of that period.
We obtain the following:

<<>>=
oilConsumptionPeriods <- data.frame(from = head(index(oilReadings), -1),
                                    to = tail(index(oilReadings), -1),
                                    oil = - diff(as.numeric(oilReadings$Total)))
# Find periods during which neither tank was filled
oilConsumptionPeriods <- with(oilReadings,
                              oilConsumptionPeriods[diff(as.numeric(Tank1)) <= 0 &
                                                      diff(as.numeric(Tank2)) <= 0, ])
oilConsumptionPeriods <- na.omit(oilConsumptionPeriods)
oilConsumptionPeriods <- transform(oilConsumptionPeriods,
                                   nDays = to - from)
@

<<>>=
climate.zoo <- zoo(subset(climate.wide, select = -Date), climate.wide$Date)
tempInInterval <- function(climate, from, to) {
  as.numeric(window(climate, start = from, end = to))
}
oilConsumptionPeriods <-
  adply(oilConsumptionPeriods,
        .margin = 1,
        .fun = mutate,
        meanTemps = I(list(tempInInterval(climate.zoo$`Bad Ragaz`, from, to))))
oilConsumptionPeriods$meanTemp <- sapply(oilConsumptionPeriods$meanTemps, mean, na.rm = TRUE)
oilConsumptionPeriods$meanTemps <- lapply(oilConsumptionPeriods$meanTemps,
                                          function(x) {
                                            x[is.na(x)] <- mean(x, na.rm = TRUE)
                                            x})
print(subset(oilConsumptionPeriods, select = -meanTemps), row.names = FALSE)
@

<<>>=
load("data/readings.RData.gz")
sargans <- do.call(merge, readings)
@

<<>>=
dailyOil <- aggregate(readings$sargans003$Oil1_volume1, function(x) floor_date(x, "day"), function(x) diff(range(x)))
index(dailyOil) <- as.Date(index(dailyOil), tz = "CET")
dailyOil <- merge(dailyOil, na.omit(climate.zoo$`Bad Ragaz`), all = FALSE)
names(dailyOil) <- c("Oil", "MeanTemp")
@

<<>>=
goodPeriods <- with(oilConsumptionPeriods[-c(5, 6), ],
	data.frame(Energy = oil,
		DailyMeans = I(meanTemps),
		When = "PRE"))
goodPeriods <- with(window(dailyOil, start = "2016-04-01"),
	rbind(goodPeriods,
		data.frame(Energy = Oil, DailyMeans = MeanTemp, When = "POST")))
goodPeriods <- goodPeriods[rownames(goodPeriods) != "2016-04-06",]
@

<<>>=
params <- estimateParameters(goodPeriods)
@

<<>>=
list2env(params$params, envir = .GlobalEnv)
@


\section{Results}

\section{Discussion}

\section{Conclusion}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\printnomenclature{}%
\end{minipage}}

\section*{References}

\bibliographystyle{elsarticle-patch}
\addcontentsline{toc}{section}{\refname}\bibliography{bibliography}

\end{document}
