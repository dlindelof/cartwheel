%% LyX 2.2.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[twoside,english,3p]{elsarticle}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\pagestyle{headings}
\usepackage{xcolor}
\usepackage{calc}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{graphicx}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecolor{lyxadded}{rgb}{0,0,1}
\providecolor{lyxdeleted}{rgb}{1,0,0}
%% Change tracking with ulem
\DeclareRobustCommand{\lyxadded}[3]{{\color{lyxadded}{}#3}}
\DeclareRobustCommand{\lyxdeleted}[3]{{\color{lyxdeleted}\sout{#3}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\newcommand{\code}[1]{\texttt{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% specify here the journal
\journal{Energy and Buildings}

% use this if you need line numbers
\usepackage{lineno}

\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{url}

\makeatother

\usepackage{babel}
\begin{document}

\begin{frontmatter}{}

\title{Bayesian evaluation of energy conservation measures: a case study
with a model-predictive controller for space heating on a commercial
building}


\author[nb]{David~Lindelöf\corref{cor1}}

\ead{david.lindelof@neurobat.net}

\author[nb]{Mohammad~Alisafaee}

\author[nb]{Pierluca~Borsò}

\author[nb]{Christian~Grigis}

\author[nb]{Xavier~Mocellin}

\author[nb]{Jean~Viaene}

\cortext[cor1]{Corresponding author}

\address[nb]{Neurobat AG, Rue de Veyrot 9, 1217 Meyrin, +41 22 552.11.62}
\begin{abstract}
Retrofitting existing buildings to improve their energy efficiency
is an investment that most building owners do eventually consider.
Faced with a variety of options, ranging from trivial (replacing light
bulbs) to major projects (better façade insulation), an owner will
want to know which energy conservation measure is likely to yield
the highest return on investment\textemdash and with what confidence.
Moreover, once the measure has been applied, the owner will want to
know how well it performs and whether their money was well spent\textemdash also
known as Measurement \& Verification.

But conventional M\&V mandates the establishment of a pre-measure
baseline, normally requiring the instrumentation of the building during
a year or more, driving the costs of M\&V to sometimes unacceptable
levels. Furthermore, a typical M\&V study will report a single number
for the measure's efficiency, ignoring (and failing to report) any
uncertainty surrounding that estimate.

To solve these two problems (expensive establishment of a baseline
and absence of uncertainty in the reported efficiency), we have developed
a method, based on Bayesian statistics, that will 1) rely on historic
utility bills and climate data to establish a baseline, and 2) estimate
the post-retrofit energy savings and report them together with suitable
confidence intervals.

We have applied this method after installing, in March 2016, a commercial
model-predictive controller for space heating for a medium-sized office
building in Switzerland. The baseline was established from historic
oil tank refill records. 55 days after installing the controller,
the energy efficiency improvement of the building was assessed and
found to have improved by 26.8\%, with 18.4 percentage points standard
error. 
\end{abstract}
\begin{keyword}
Bayesian inference \sep heating degree-days\sep base temperature\sep
balance point temperature\sep total heat loss coefficient\sep heating
base load
\end{keyword}

\end{frontmatter}{}

<<setup, include=FALSE>>=
library(homeR)

library(dplyr)
library(ggplot2)
library(lubridate)
library(MCMCpack)
library(plyr)
library(reshape2)
library(xtable)
library(zoo)

theme_set(theme_bw())

opts_chunk$set(error = FALSE, warning = FALSE, echo = FALSE, message = FALSE,
			   results = 'hide',
               dev = "tikz", dev.args = list(pointsize = 10),
               fig.width = 3.5, fig.height = 3.5, fig.align = "center")

source("inference3.R")
p <- function(x) formatC(x, digits = 1, format = 'f') 
@

\section{Introduction}

Many energy conservation measures (ECM\nomenclature{ECM}{Energy Conservation Measure})
exist to reduce the consumption of energy in existing buildings, but
vary widely in effectiveness. Faced with a variety of options, ranging
from trivial (replacing light bulbs) to major projects (better façade
insulation), an owner will want to know which energy conservation
measure is likely to yield the highest return on investment\textemdash and
with what confidence. Moreover, once the measure has been applied,
the owner will want to know how well it performs and whether their
money was well spent\textemdash an activity known as Measurement \&
Verification (M\&V).

This is a recurring problem for large companies in Switzerland that
have publicly committed themselves to reducing their greenhouse gas
emissions. The majority of these emissions can be traced to large
portfolios of legacy buildings, in particular to the fossil fuels
used for heating. Reducing the heating energy for legacy buildings
(while maintaining user comfort) will help such companies achieve
their objectives\textemdash provided those energy savings can be proven.
Given a choice between ECMs, a facility manager will frequently favor
those perceived as being of relatively low-risk, even when their effectiveness
might be less attractive.

But doing M\&V well is hard. Many factors influence the energy consumption
of a building, and they must be accounted for before and after the
installation of the ECM. Proper M\&V typically involves the establishment
of a ``baseline'' model of the building's energy consumption\textemdash usually
over at least one year. The measured energy consumption post-retrofit
is then compared with the energy consumption predicted by the baseline
model, yielding the energy savings, either in absolute terms or in
relative. But many M\&V projects ignore the uncertainties surrounding
the baseline model and report a point estimate for the energy savings,
giving a false sense of accuracy.

Lack in confidence in the effectiveness of ECMs limit their adoption
(\citet{Ma2012}). To convince building owners to undertake more building
retrofit projects we must address two concerns that are frequently
expressed: 1) the risk that the ECM might not be as effective as advertised,
and 2) the risk that, although effective, the benefits will turn out
to be difficult to prove. The latter is the goal of M\&V, which currently
suffers from an image of (bad) science, or of ``an inaccurate science:
an engineering practice relying heavily on professional judgement''
(\citet{Xia2013}). We must show building owners that assessing the
effectiveness of ECMs is not a research project anymore but a well-defined
and well-understood process, one that yields not just the estimated
energy savings but also their accuracy and confidence.

\subsection{The International Performance Measurement and Verification Protocol}

The International Performance Measurement and Verification Protocol
\citep{evo2012} is a widely recognized framework for conducting M\&V
projects. It provides a set of guidelines and documents common terms
and methods for such projects. Energy savings are to be determined
by first establishing the building's pre-retrofit baseline energy
demand. After the installation, the energy demand is measured again,
resulting in a so-called reporting period demand. Energy savings are
calculated from the difference between the basline and reporting period
demand, taking also in to account external factors that influence
the energy demand:
\[
\text{Savings}=(\text{Baseline-period demand - Reporting-period demand)}\pm\text{Adjustments}
\]
 The IPMVP leaves no doubt on the need for quantifiable uncertainties:
\begin{quote}
In order to communicate savings in a statistically valid manner, savings
need to be expressed along with their associated confidence and precision
levels. \citep[p. 88]{evo2012}
\end{quote}
Indeed the whole point of M\&V projects is to \emph{reliably} determine
energy savings. Although the definition of ``reliably'' rests ultimately
on the user of the M\&V report, the IPMVP suggests that savings, to
be statistically significant, should be at least twice the standard
error of the baseline energy consumption \citep[p. 88]{evo2012}.
(When some sampling is used to estimate the basline demand, the sampling
should be designed to yield a \textpm 10\% relative precision and
90\% confidence level.)

But ultimately, the IPMVP recognises that the user of the M\&V report
is the party responsible for establishing acceptable savings accuracy
during the M\&V Planning process. 

\subsection{Recent assessments}

A Scopus search for the ``IPMVP'' term in a document's title, abstract
or keywords, limited to publication date from 2010 to present, yields
37 documents. Of these, just 3 study the energy efficiency of an ECM
without resorting to computer simulation. They were:
\begin{itemize}
\item \citet{Aris2015}: retrofit of a water cooling package unit. Baseline
consumption July 2012 to June 2013 modeled as linear combination of
occupancy, number of working days and cooling degree-days. Calculates
energy avoided from August 2013 to July 2014. t-test finds no statistically
significant energy savings.
\item \citet{Ginestet2010} applies the IPMVP to an existing building equipped
with a new HVAC device. The energy savings are determined by 1) simulation
and 2) by retrofitting one room and leaving another one unchanged.
\item \citet{Kaiser2010} reports on the results from a large-scale program
where 730 households participated, and 150 are chosen at random. Baseline
established as linear model in HDD, CDD, relative humidity and energy
price. No uncertainties are reported.
\end{itemize}
Other retrofit assessments found in the literature include:
\begin{itemize}
\item \citet{Cohen1991} old but relevant: 32 retrofit projects, ranging
in size from three to 30 000 houses. Energy normalised by HDD using
fixed 65 F. Mix of submetered, utility bills.
\item \citet{Lin2015} Electricity and gas bill for a 31'000\,m\textsuperscript{2}
campus whose HVAC equipment was retrofitted. IMPVP option C. Baseline
from Sept 2007 to August 2008. Measurement from May 2009 to April
2010. Normalised to outdoor temperature. Savings reported without
uncertainty.
\item \citet{Walter2014} Models electric load as function of time of week
and outdoor temperature. Nonlinear dependency on outdoor temperature.
Cross-validation used to quantify uncertainty in baseline estimation.
Having access to full-year of data does not necessarily improve baseline
estimates. 17 buildings analysed. Half have 27 months of data, other
half 12. Method is a good indicator for predicting baseline error
for a single month (the last one), but uncertainties highly variable
from building to building.
\end{itemize}
Notes that when using the energy avoided (need to check the term)
method, the uncertainty is entirely due to the uncertainty in the
baseline.

When uncertainty in baseline higher than expected savings, no savings
can be proved.

\section{Experimental building}

The Sargans building shown in Fig.~\ref{fig:composite} includes
four heating circuits, covering about 2'700\textendash 2'800 m\textsuperscript{2},
with heating water provided by an oil-fired boiler. The NOL\textsuperscript{a}
system was installed in March 2016 on three of the four circuits,
commonly referred to as Neubau, Büro, and Wohnung, the latter two
belonging to the old part of the building (Altbau). The fourth circuit
was deemed not to require optimisation, as the zone in question is
kept relatively cool. The total surface covered by NOL\textsuperscript{a}
is about 1'300\textendash 1'400 m\textsuperscript{2}.

The oil-fired boiler draws its fuel from two tanks and provides the
heating water to all heating circuits. The levels in the tanks are
recorded at irregular intervals, such as when either (or both) tank
was refilled. The domestic hot water is provided by an independent
circuit.

Improving the heating system's controller (such as by replacing it
with a model-predictive controller) belongs to the ECM category of
``Energy efficient equipment and low energy technologies'', a form
of demand side management.

Neurobat\textquoteright s adaptive model-predictive control algorithm
regularly calculates an optimal value for the temperature of the water
prepared by the oil boiler. This value cannot be communicated directly
to most legacy heating controllers; instead, the NOL\textsuperscript{a}
system controls the flow temperature indirectly by shifting the outdoor
temperature measured by the heating controllers. Thus, the boiler
provides for each circuit a heating water at just the right temperature.

The sensors attached to the NOL\textsuperscript{a} system (including
an oil meter) are automatically sampled several times per hour and
stored in a database. The data is used for monitoring in near real
time, and for offline data analysis.

\begin{figure}
\begin{centering}
\includegraphics[width=0.8\columnwidth]{img/sargans_composite}
\par\end{centering}
\caption{Aerial (top left) and side views of the Altbau (bottom) and Neubau
(right) parts of the Sargans building. The Büro and Wohnung circuits
belong to the Altbau part.}

\label{fig:composite}
\end{figure}


\section{Bayesian energy model}

The energy consumed by a building is rarely constant but varies over
time due to so-called routine factors (expected to vary, such as the
climate) and non-routine factors (normally constant, such as the indoor
temperature setpoint or the function of the building). These factors
must be accounted for when assessing the effectiveness of an ECM.
This is normally done by establishing a model for the energy use before
and after the installation of the ECM, as we do here.

Under normal conditions, the daily heating demand of a building will
balance the building's heat loss. The daily losses $Q_{d}$ on a day
$d$ can be modeled as a random variable drawn from a Gaussian distribution,
whose mean is proportional to the positive difference between the
average outdoor temperature and the building's \emph{base temperature}:
\begin{equation}
Q_{d}=K\times(t_{\text{b}}-\overline{t_{\text{out}}}_{d})^{+}+\mathcal{N}(0,\sigma^{2})
\end{equation}
 where the base temperature $t_{\text{b}}$ of a building is defined
as the outdoor temperature above which all heat losses are compensated
by the sun and other free gains. $K$ is the building's \emph{total
heat loss coefficient}, the quantity of extra heat required per day
to maintain indoor comfort for each extra degree of cold. It is the
most important metric when assessing the efficacy of a new heating
control algorithm.

Over a period $p$ made up of $n_{p}$ days, the total heating load
will be 
\begin{equation}
Q_{p}=\sum_{d\in p}Q_{d}=K\times DD_{p}+\mathcal{N}(0,n_{p}\sigma^{2})\label{eq:Qp}
\end{equation}
where $DD_{p}=\sum_{d\in p}(t_{\text{b}}-\overline{t_{\text{out}}}_{d})^{+}$
is the number of \emph{degree-days at base temperature $t_{\text{b}}$}
during that period. $Q_{p}$ is frequently available as utility bills
or energy meter readouts, while $DD_{p}$ must be calculated from
historic weather data and the building's estimated base temperature.

The set of utility bills (or energy meters readouts) $Q_{p}$ constitutes
the data we have at hand, while Eq.\ \eqref{eq:Qp} is a probability
model from which that data is drawn. Bayesian inference consists now
in ``fitting a probability model to a set of data and summarizing
the result by a probability distribution on the parameters of the
model and on unobserved quantities such as predictions for new observations''
(\citet{Gelman2013}).

Letting $D$ stand for the set of reporting periods (for example,
a set of monthly gas utility bills, or a list of oil tank level readouts),
Bayesian inference consists in establishing the probability density
function for the coefficients $\{K,\theta_{\text{b}},\sigma\}$ conditioned
on the information $D$, noted as $p(\{K,\theta_{\text{b}},\sigma\}\mid D)$.
A method to carry out this inference has been presented by \citep{Lindelof2016}
and implemented by the \code{bhm()} function in the \code{homeR}
R package \citep{homeR}. Unlike that prior work, where the focus
was on the determination of a building's base temperature, here we
will be more concerned with $K$, the building's heat loss coefficient.
We will use the pdf computed for this set of parameters to make inferences
about the parameter $K$ before and after the retrofit.

Installing an ECM such as the NOL\textsuperscript{a} will alter the
building's total heat loss coefficient by a factor $\rho$, and also
possibly shift the base temperature if the indoor setpoints are not
exactly identical before and after the installation: 
\[
K_{\mathrm{pre}}\rightarrow K_{\mathrm{post}}=\rho\times K_{\mathrm{pre}}
\]
\[
t_{\text{b},\text{pre}}\rightarrow t_{\text{b},\mathrm{post}}=\Delta t_{\text{b}}+t_{\text{b},\mathrm{pre}}
\]
A shift in the building's base temperature $\theta_{\text{b}}$ was
considered as unavoidable, since nothing was known about the normal
indoor temperature setpoints before the retrofit. It was therefore
agreed that the efficacy of the ECM would be entirely quantified by
the ratio $\rho$ between the pre- and post-installation heat loss
coefficients. The lower $\rho$ is, the higher the energy savings.
The relative energy savings in percent will be given by $100\times(1-\rho)$.

Hardcore Bayesians would now write a full probability model involving
all the pre- and post-installation parameters, work out the joint
posterior probability density function, draw samples from that function
and make inferences. There's nothing wrong with this, but we believe
the pre- and post-installation parameters should be taken as being
independent; for example, the pre-retrofit heating loss coefficient
$K_{\text{pre}}$ should be considered as completely independent from
its post-retrofit counterpart $K_{\text{post}}$, and the same holds
for the base temperature $\theta_{\text{b}}$. (It could be argued
that we expect the post-retrofit heating loss coefficient to be smaller
that the pre-retrofit one; but full objectivity requires us to consider
the pre- and post-conditions as perfectly exchangeable. And the only
relationship between the two that satisfies full exchangeability is
one of full independence.) But if the pre- and post-retrofit parameters
are independent, then we are effectively dealing with two independent
experiments: one before the installation, and one after. The Bayesian
analysis can therefore be simplified by considering separately the
pre- and post-conditions.

(One could argue that the measurement noise $\sigma$ should \emph{not}
be considered as independent; in fact, it would be reasonable to consider
it as the same before and after the retrofit. We would normally agree
with that; but $\sigma$expresses not only the daily inherent variability
in energy consumption of the building: it also includes measurement
errors. Since the oil consumption has been measured with two completely
different methods before and after the retrofit, we prefer to treat
$\sigma_{\text{pre}}$ and $\sigma_{\text{post}}$ as two independent
parameters.)

Putting it together formally, the task consists in establishing $p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}},K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D)$
where $D$ now stands for the union of the pre- and post-installation
data $D_{\text{pre}}$ and $D_{\text{post}}$. If we assume that the
parameters before and after the retrofit are independent, we have
\begin{align*}
p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}},K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D) & = & p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}}\}\mid D)\times p(\{K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D)\\
 & = & p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}}\}\mid D_{\text{pre}})\times p(\{K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D_{\text{post}})
\end{align*}
where each term on the right-hand side can be computed by the method
proposed by \citet{Lindelof2016}.

The analysis of the historic weather and oil consumption data will
be explained in the following sections, followed by the analysis of
the new consumption data. 

\section{Historic weather and oil consumption data}

The International Performance Measurement and Verification Protocol
(IPMVP) requires an auditor to establish the performance of the building
before the installation of the ECM (the \emph{baseline} period) and
after (the \emph{reporting} period). Unlike traditional IPMVP projects,
this pilot building is challenging because daily oil consumption readouts
were available only after the installation of the NOL\textsuperscript{a}.
The energy savings must therefore be derived from heterogenous sources
of data: manual oil level readouts before the installation, and automated
daily oil readouts after. Traditional analysis methods have trouble
dealing with such situations, especially for estimating a building's
base temperature from historic utility bills. We have developed a
method based on Bayesian statistical methods, that can deal with such
data and derive the heat loss coefficient before and after the installation.
The details are out of scope of this report, but the full method is
described in a paper submitted for publication in an upcoming issue
of Energy \& Buildings, and recently accepted pending minor revisions.
The algorithm has been implemented as the \code{bhm()} function in
Neurobat's \code{homeR} R package, freely available from CRAN \citep{homeR}
.

\subsection{Weather data}

The historic weather data (going back to 2011) is obtained from \citet{meteosuisse2016},
who provides a file with average daily temperatures measured in Bad
Ragaz (about 6 km from Sargans) and Vaduz (about 10 km). The relative
positions of the pilot building in Sargans and of the Bad Ragaz and
Vaduz weather stations are shown in Fig.~\ref{fig:stations} in the
Appendix. The data from the stations is shown against time in Fig.~\ref{fig:ClimatePlot}.
A scatterplot of the temperatures from Bad Ragaz against those from
Vaduz is shown in Fig.~\ref{fig:ClimateScatterPlot}. There are no
obvious differences between the two weather stations. From here onwards,
we use the data from Bad Ragaz. 

<<>>=
climate2 <- read.table("data/RAD_VAD.txt",
  skip = 10,
  na.strings = "32767",
  colClasses = c(V1 = "factor"))
climate2 <- transform(climate2, Date = as.Date(ymd(paste(V2, V3, V4, sep = "-"))))
climate2 <- subset(climate2, select = c(1, 8, 7))
names(climate2) <- c("Station", "Date", "Temperature")
levels(climate2$Station) <- c("Bad Ragaz", "Vaduz")
climate <- climate2
climate.wide <- dcast(climate, Date ~ Station) 
@

<<ClimatePlot, fig.cap="Historic outdoor temperature measured at nearby weather stations. There is no obvious disagreement between the stations.", fig.width=5, fig.height=3>>=
ggplot(climate, aes(Date, Temperature, color = Station)) +
	geom_line() +
	xlim(as.Date("2010-12-20"), as.Date("2016-04-30")) +
	theme(legend.position="top")
@

<<ClimateScatterPlot, fig.cap="Comparison of Bad Ragaz and Vaduz temperatures.", fig.width=4>>=
ggplot(climate.wide, aes(`Bad Ragaz`, Vaduz)) + geom_point(size = 1) + coord_fixed() 
@

\subsection{Baseline oil consumption}

The historic oil consumption data consists in a sheet of paper used
to log the readouts of the oil levels in the boiler's tanks. A copy
of the original paper is shown in Fig.~\ref{fig:readouts} in the
Appendix. The cleaned version is shown in Table~\ref{tab:oilReadouts}.

<<results='asis'>>=

oilReadingsDf <- read.table(text = "
Date        Tank1  Tank2
2011-02-03   7500  13300
2011-05-25   5500  13000
2011-10-25   4000  13000
2011-11-25  10700     NA
2012-02-23  10500   3300
2012-04-10  10000    500
2012-05-02     NA  11100
2012-05-27   8000  10500
2013-01-15  10000  10300
2013-03-06  10000   5200
2013-06-17  10000   5000
2013-08-15   9500      0
2013-08-15  13450  12500
2013-11-27  13437   8800
2014-07-25   9500    500
2014-09-24   9000    500
2014-09-24   9000  12500
2014-11-18   7000  12500
2014-11-18   9100  12500
2014-12-03   7400  12500
2015-02-10     NA  12400
2015-03-25      0   7500
2015-06-10  13200  10000
2015-12-15  13200   3500
2016-03-08   8500     NA
",
                          header = TRUE,
                          colClasses = c(Date = "Date"))
oilReadingsDf <- transform(oilReadingsDf, Total = Tank1 + Tank2)
oilReadings <- zoo(oilReadingsDf[,-1], order.by = oilReadingsDf$Date)
betweenReadings <- (function(x) diff(x) / diff(range(x))) (as.numeric(oilReadingsDf$Date))

# call to as.character is a workaround for https://r-forge.r-project.org/tracker/?func=detail&group_id=1228&aid=6465&atid=4864
print(xtable(transform(oilReadingsDf, Date = as.character(Date)),
			 caption = "Transcribed oil level readouts. White space has been added between rows proportional to the time elapsed between two readings.",
			 label = "tab:oilReadouts"),
      booktabs = TRUE,
      include.rownames = FALSE,
      add.to.row = list(pos = as.list(1:(nrow(oilReadingsDf)-1)), command = paste('[', 50*betweenReadings, "mm]", sep='')))
@

There are log entries (for example 2012-05-02) when one tank was filled
without recording its level before the refill. In such instances it
is impossible to know how much oil was used during the preceding period.
We therefore restrict this data to the 12 periods \emph{during which
neither tank level increased}.

Each period is matched with its historic weather data, yielding a
list of mean daily outdoor temperatures for each day of that period.
We obtain the following:

<<>>=
oilConsumptionPeriods <- data.frame(from = head(index(oilReadings), -1),
                                    to = tail(index(oilReadings), -1),
                                    oil = - diff(as.numeric(oilReadings$Total)))
# Find periods during which neither tank was filled
oilConsumptionPeriods <- with(oilReadings,
                              oilConsumptionPeriods[diff(as.numeric(Tank1)) <= 0 &
                                                      diff(as.numeric(Tank2)) <= 0, ])
oilConsumptionPeriods <- na.omit(oilConsumptionPeriods)
oilConsumptionPeriods <- transform(oilConsumptionPeriods,
                                   nDays = to - from)
@

<<results='asis'>>=

climate.zoo <- zoo(subset(climate.wide, select = -Date), climate.wide$Date)
tempInInterval <- function(climate, from, to) {
  as.numeric(window(climate, start = from, end = to))
}
oilConsumptionPeriods <-
  adply(oilConsumptionPeriods,
        .margin = 1,
        .fun = mutate,
        meanTemps = I(list(tempInInterval(climate.zoo$`Bad Ragaz`, from, to))))
oilConsumptionPeriods$meanTemp <- sapply(oilConsumptionPeriods$meanTemps, mean, na.rm = TRUE)
# Days with missing data are imputed with mean temperature of their period
oilConsumptionPeriods$meanTemps <- lapply(oilConsumptionPeriods$meanTemps,
                                          function(x) {
                                            x[is.na(x)] <- mean(x, na.rm = TRUE)
                                            x})
oilConsumptionPeriodsTable <- xtable(oilConsumptionPeriods)
oilConsumptionPeriodsTable <- dplyr::select(oilConsumptionPeriodsTable, -meanTemps)
oilConsumptionPeriodsTable <- dplyr::select(oilConsumptionPeriodsTable, from = as.character(from))
oilConsumptionPeriodsTable <- dplyr::select(oilConsumptionPeriodsTable, to = as.character(to))
print(oilConsumptionPeriodsTable, row.names = FALSE)
@

<<>>=
load("data/readings.RData.gz")
sargans <- do.call(merge, readings)
@

<<>>=
dailyOil <- aggregate(readings$sargans003$Oil1_volume1, function(x) floor_date(x, "day"), function(x) diff(range(x)))
index(dailyOil) <- as.Date(index(dailyOil), tz = "CET")
dailyOil <- merge(dailyOil, na.omit(climate.zoo$`Bad Ragaz`), all = FALSE)
names(dailyOil) <- c("Oil", "MeanTemp")
@

<<>>=
goodPeriods <- with(oilConsumptionPeriods[-c(5, 6), ],
	data.frame(Energy = oil,
		DailyMeans = I(meanTemps),
		When = "PRE"))
goodPeriods <- with(window(dailyOil, start = "2016-04-01"),
	rbind(goodPeriods,
		data.frame(Energy = Oil, DailyMeans = MeanTemp, When = "POST")))
goodPeriods <- goodPeriods[rownames(goodPeriods) != "2016-04-06",]
@

<<>>=
params <- estimateParameters(goodPeriods)
@

<<>>=
list2env(params$params, envir = .GlobalEnv)
@

Note that two records in the oil readouts are probably erroneous and
should be excluded from the analysis: 
\begin{enumerate}
\item From 2013-03-06 to 2013-06-17 (103 days): 200 L, or about 2 L per
day
\item From 2013-06-17 to 2013-08-15 (59 days): 5500 L, or about 100 L per
day during summer
\end{enumerate}
The building's base temperature and heat loss coefficient are estimated
from this data using our method. We obtain $t_{\text{b}}=\Sexpr{p(baseTempPre)}\pm\Sexpr{p(sqrt(params[["covariance"]][2,2]))}$
C, and $K_{\mathrm{pre}}=\Sexpr{p(Kpre)}\pm\Sexpr{p(sqrt(params[["covariance"]][1,1]))}$
L/C.

Now that we have the building's base temperature, we can validate
it by calculating the number of degree days for each oil consumption
period and plotting the oil consumed during each period against the
degree days of that period. If the base temperature is correct, we
should obtain points lying on a straight line that goes through the
origin. We show this in Fig.~\ref{fig:OilVsDD}, where for comparison
we do the same with degree days calculated with different official
standards. The Bayesian method yields the best results. The relationship
between the oil consumption and the degree days using the estimated
base temperature is satisfactorily linear, with the exception of the
two outliers identified above (not plotted), and possibly a third
point with 2300 liters of oil for about 750 degree days. 

<<OilVsDD, fig.cap="Oil consumption vs heating degree days, calculated with different base temperatures. The Bayesian base temperature yields the highest coefficient of determination $R^2$, showing that it fits the data best.">>=
DD <- function(dailyTemps, base) sum(pos(base - dailyTemps))
before.dd <- subset(goodPeriods, When == "PRE")
before.dd$Bayesian <- sapply(before.dd$DailyMeans, DD, baseTempPre)
before.dd$ASHRAE <- sapply(before.dd$DailyMeans, DD, 18.3)
before.dd[["SIA 380:2015"]] <- sapply(before.dd$DailyMeans, DD, 12)
before.dd[["Carbon Trust"]] <- sapply(before.dd$DailyMeans, DD, 15.5)
before.dd[["SIA 381/3"]] <- sapply(before.dd$DailyMeans, function(x) sum(ifelse(x < 12, 20 - x, 0)))
before.dd.long <- melt(before.dd, 
	id.vars = "Energy", 
	measure.vars = c("Bayesian", "ASHRAE", "SIA 380:2015", "Carbon Trust", "SIA 381/3"),
	variable.name = "Base",
    value.name = "Degree days")
before.rsq <- ddply(before.dd.long, 
	.(Base), 
	function(x) summary(lm(Energy ~ `Degree days`, x))$r.squared) 
before.rsq$label <- format(before.rsq$V1, di = 3)
ggplot(before.dd.long, aes(`Degree days`, Energy)) +
	geom_point() +
	facet_wrap(~ Base) +
	geom_smooth(method = "lm", formula = y ~ x, se = FALSE) + 
	geom_text(data = before.rsq, aes(1200, 2500, label = paste("italic(R)^2=='", label, "'"), hjust = 0), parse = TRUE, size = rel(3)) +
	ylab("Oil [L]")
@

\section{Reporting period}

After the installation of the two NOL\textsuperscript{a} systems,
we had access to daily oil consumption data thanks to an oil counter.
With this data we can correlate the oil consumption with the outdoor
temperature on a daily basis, instead of having to wait until the
next oil tank refill. That relationship is shown in Fig.~\ref{fig:Signature}. 

<<Signature, fig.cap="Daily oil consumption vs daily average outdoor temperatures. A linear fit is shown with its confidence bands.">>=
signature <- qplot(as.numeric(DailyMeans), 
	Energy,
	data = subset(goodPeriods, When == "POST"),
	xlab = "Mean outdoor temperature [C]",
	ylab = "Oil [L]") +
	geom_smooth(method = "lm")
signature
@

Each point in this plot represents one day, and we restrict the data
to dates after 1st April 2016 when a mislabeling of the existing heating
system was identified and corrected. The post-installation total heat
loss coefficient $K_{\mathrm{post}}$ is the slope of the linear regression
through these points, since each point represents one day of oil consumption
and they all are lower than the base temperature. We obtain $K_{\mathrm{post}}=\Sexpr{p(Kpost)}\pm\Sexpr{p(sqrt(params[['covariance']][4,4]))}$
L/C, or about 30\% less than the pre-installation total heat loss
coefficient $K_{\mathrm{pre}}$.

\section{Results}

<<cache=TRUE>>=
metropfun <- function(x, periods)
  do.call(loglikelihood, args = c(list(periods), as.list(c(x[1:2], 0, x[3:5]))))
metropfun3 <- function(x, periods)
  do.call(loglikelihood, args = c(list(periods), as.list(c(x[1:2], 0, x[3:6]))))
#m <- MCMCmetrop1R(metropfun, c(U, baseTemp, sigma, rho, DbaseTemp), seed = 1345, tune = 1.3, periods = goodPeriods)
m3 <- MCMCmetrop1R(metropfun3, c(Kpre, baseTempPre, sigmaPre, Kpost, baseTempPost, sigmaPost), seed = 1345, tune = 1.3, periods = goodPeriods)
m <- m3
m <- cbind(m, 1 - m[, 4] / m[, 1])
colnames(m) <- c("Kpre", "baseTempPre", "sigmaPre", "Kpost", "baseTempPost", "sigmaPost", "savings")
@

<<>>=
HDIofMCMC <- function(samples, credMass = 0.95) {
  sortedSamples <- sort(samples)
  nInCI <- ceiling(credMass * length(samples))
  nCandidateCI <- length(samples) - nInCI
  CIWidths <- rep(0, nCandidateCI)
  for (i in 1:nCandidateCI) {
    CIWidths[i] <- sortedSamples[i + nInCI] - sortedSamples[i]
  }
  HDImin <- sortedSamples[which.min(CIWidths)]
  HDImax <- sortedSamples[which.min(CIWidths) + nInCI]
  c(HDImin, HDImax)
}
@

<<>>=
rhoCI <- HDIofMCMC(m[, 'Kpost'] / m[, 'Kpre'], 0.67)
rho <- mean(rhoCI)
Drho <- diff(rhoCI) / 2
@

<<>>=
rhocdf <- ecdf(m[, 'savings'])
savingsPercent <- 100 * (1 - rho)
savingsError <- 100 * Drho
@

The increase in energy efficiency resulting from the NOL\textsuperscript{a}
installation can now be evaluated, defined as $(1-K_{\mathrm{post}}/K_{\mathrm{pre}})$.
But our Bayesian method does not compute point estimates; instead,
it computes how \emph{probable} the energy savings are given the data;
or rather, it computes the \emph{probability density} for each possible
value of those savings. A histogram of that probability density is
shown in Fig.~\ref{fig:RhoDensity}. The majority of that histogram
is positive, indicating positive energy savings. Any statement about
the energy savings can now be made with its associated confidence.
For example, 75\% of the mass of this histogram lies to the right
of 14\% energy savings; this can be reported by saying that the energy
savings are at least 14\% with 75\% probability. The `best' estimate
of the final energy savings is obtained by finding the narrowest range
of energy savings such that they encompass $N$\% of the mass of the
histogram, also known as the $N$\% credible interval, for any desired
value for $N$. Since one standard error of a normal distribution
corresponds to a 67\% credible interval, we will report the energy
savings with the same value for $N$. We obtain:
\begin{center}
Relative savings = $\Sexpr{p(savingsPercent)}\pm\Sexpr{p(savingsError)}$
(67\% credible interval).
\par\end{center}

An uncertainty of $\Sexpr{p(savingsError)}$\% may sound large and
it is tempting to try and reduce that error by letting the experiment
run longer. But letting the experiment run longer will only reduce
the error on the post-installation heat loss coefficient $K_{\text{post}}$;
there is nothing we can do about the error on the pre-installation
heat loss coefficient $K_{\text{pre}}$, which dominates the total
error on the final energy savings. The absolute error on the savings,
which are equal to the absolute error on $\rho$, have a lower limit
given by the relative error on $K_{\text{pre}}$: $\Delta\rho\geq\rho\times\Delta K_{\text{pre}}/K_{\text{pre}}$.
In our case, $\rho=\Sexpr{p(rho)}$, $\Delta K_{\text{pre}}=\Sexpr{p(sd(m[,'Kpre']))}$,
$K_{\text{pre}}=\Sexpr{p(mean(m[,'Kpre']))}$ and therefore $\Delta\rho\geq\Sexpr{p(mean(m[,'Kpost']/m[,'Kpre'])*sd(m[,'Kpre'])/mean(m[,'Kpre']))}$,
very close to the current uncertainty of $\Sexpr{p(savingsError)}$\%.
After $\Sexpr{nrow(subset(goodPeriods,When='POST'))}$ days of measurements
after the installation, our accuracy is almost as good as it will
ever get. 

<<RhoDensity, fig.cap="Probability density distribution for the relative energy savings in percent. The red line indicates the best estimate and the blue bars indicate the 67\\% credible interval.">>=
q <- qplot(100 * m[, 'savings'], y = ..density.., geom = "histogram", xlab = "Relative energy savings [\\%]", ylab = "Probability density")
q +
  geom_vline(xintercept = savingsPercent, color = "red", lwd = 2) +
  annotate("segment", x = savingsPercent - savingsError, xend = savingsPercent + savingsError,
           y = 0.007, yend = 0.007, colour = "blue", lwd = 2, arrow = arrow(ends = "both", angle = 90, length = unit(.2, "cm"))) +
  xlim(-100, 100)
@

With this probability density one can answer any question about the
energy savings on that building, such as \textquotedbl{}What are the
most likely energy savings?\textquotedbl{}, \textquotedbl{}What energy
savings can I expect on average?\textquotedbl{}, or \textquotedbl{}How
likely am I to achieve energy savings of at least 20\%?\textquotedbl{}.
The latter kind of questions are answered in Table~\ref{tab:probs},
showing, for any level of energy savings, how likely one is to achieve
at least that level. 

<<results='asis'>>=
savingsProbability <- data.frame(Savings = seq(0, 40, by = 5))
savingsProbability$Probability <- 100 * (1 - rhocdf(savingsProbability$Savings / 100))
names(savingsProbability) <- c("Savings [%]", "Probability [%]")
print(xtable(savingsProbability, label = "tab:probs", caption = "Probability that the true energy savings are higher than a given level."), include.rownames = FALSE, comment = FALSE)
@

The following caveats should, however, be kept in mind:
\begin{itemize}
\item We have assumed that the building's base temperature and heat loss
coefficient have remained constant from 2011\textendash 2015.
\item We have assumed that a linear relationship holds between the oil consumption
and the average outdoor temperature post-installation, but the plot
above suggests a good deal of variance that must be attributed to
other factors than the outdoor temperature. We have anectodal evidence
that this happens on other Neurobat-controlled sites. We conjecture
that the solar irradiance plays a more important part in a building's
energy signature when it is controlled by Neurobat than with a heating-curve
based controller.
\item Fig. suggests that the building's base temperature may have shifted
upwards after the installation of the NOL\textsuperscript{a} systems.
This happens when the temperature setpoint programmed on the NOL\textsuperscript{a}
is higher than the average temperature kept by the original heating
system. But historic indoor temperatures are rarely available, and
the NOL\textsuperscript{a} installer relies on the temperature setpoint
programmed on the original heating system\textemdash which can be
very different from the temperature really desired by the user. This
does not invalidate the above analysis, but the building manager should
consider adjusting those setpoints to fully reap the energy savings.
\end{itemize}

\section{Discussion}

\section{Conclusion}

Model-predictive control of space heating has reduced the oil consumption
of the Sargans building by almost a third\textemdash the equivalent
of having walls about 40\% thicker, at a fraction of the cost of traditional
insulation. According to the building's Object Manager, the users
are satisfied with the comfort provided by NOL\textsuperscript{a}
and has received no complaints, whether from tenants or employees.

This pilot installation has satisfactorily demonstrated the potential
of the Neurobat technology for non-residential buildings, where several
heating circuits, fed by the same boiler, need to be optimised simultaneously. 

\section*{Appendix}

\subsection*{Map of the Sargans area}

The map in Fig.~\ref{fig:stations} shows the location of Sargans
and of the closest weather stations in Bad Ragaz and Vaduz.

\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/map}
\par\end{centering}
\caption{Relative positions of Sargans and the two weather stations}
\label{fig:stations}

\end{figure}


\subsection*{Original oil readouts}

Fig.~\ref{fig:readouts} shows the original oil readouts, from which
the pre-installation energy performance was derived.

\begin{figure}
\begin{centering}
\includegraphics[width=0.8\textwidth]{img/oil}
\par\end{centering}
\caption{The original manual oil level readouts}
\label{fig:readouts}
\end{figure}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\settowidth{\nomlabelwidth}{ECM}
\printnomenclature{}%
\end{minipage}}

\section*{References}

\bibliographystyle{elsarticle-patch}
\addcontentsline{toc}{section}{\refname}\bibliography{bibliography}

\end{document}
