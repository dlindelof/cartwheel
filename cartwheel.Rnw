%% LyX 2.2.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\documentclass[twoside,english,5p, sort&compress]{elsarticle}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\pagestyle{headings}
\usepackage{xcolor}
\usepackage{calc}
\usepackage{textcomp}
\usepackage{mathtools}
\usepackage{amsmath}
\usepackage{graphicx}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}
\usepackage{nomencl}
% the following is useful when we have the old nomencl.sty package
\providecommand{\printnomenclature}{\printglossary}
\providecommand{\makenomenclature}{\makeglossary}
\makenomenclature
\usepackage{subscript}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.
\providecolor{lyxadded}{rgb}{0,0,1}
\providecolor{lyxdeleted}{rgb}{1,0,0}
%% Change tracking with ulem
\DeclareRobustCommand{\lyxadded}[3]{{\color{lyxadded}{}#3}}
\DeclareRobustCommand{\lyxdeleted}[3]{{\color{lyxdeleted}\sout{#3}}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
% specify here the journal
\journal{Energy and Buildings}

% use this if you need line numbers
\usepackage{lineno}

\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{siunitx}
\usepackage{tabularx}
\usepackage{url}

\renewcommand\nomname{Notation}

\makeatother

\usepackage{babel}
\begin{document}

\begin{frontmatter}{}

\title{Bayesian evaluation of energy conservation measures}


\author[nb]{David~Lindelöf\corref{cor1}}

\ead{david.lindelof@neurobat.net}

\author[nb]{Mohammad~Alisafaee}

\author[nb]{Pierluca~Borsò}

\author[nb]{Christian~Grigis}

\author[nb]{Jean~Viaene}

\cortext[cor1]{Corresponding author}

\address[nb]{Neurobat AG, Rue de Veyrot 9, 1217 Meyrin, +41 22 552.11.62}
\begin{abstract}
Most building owners eventually invest in energy conservation measures
for their buildings. Faced with a variety of options, ranging from
trivial (replacing light bulbs) to major (better façade insulation),
they want to know which measure will yield the highest return on investment\textemdash and
with what confidence. Moreover, once the measure has been applied,
they want to know how well it performs and whether their money was
well spent\textemdash also known as Measurement \& Verification.

But conventional M\&V mandates the establishment of a pre-measure
baseline. The building should be instrumented during a year or more
before applying the measure, driving the costs of M\&V to sometimes
unacceptable levels. Furthermore, a typical M\&V study will report
a single number for the measure's efficiency, ignoring any uncertainty
surrounding that estimate.

To solve these two problems (expensive baseline and absence of uncertainty),
we have developed a method, based on Bayesian statistics, that will
1) rely on historic utility bills and climate data to establish a
baseline, and 2) estimate, with confidence intervals, how effective
the energy conservation measure was.

We have tested this method after installing, in March 2016, a model-predictive
controller for space heating for a medium-sized (about 2700\,m\textsuperscript{2})
office building in Switzerland. The baseline was established from
historic oil tank refill records and climate data from a nearby weather
station. The total heat loss coefficient of the building was assessed
46 days after the installation and found to have decreased by 33.1\%,
with 19.0 percentage points standard error. 
\end{abstract}
\begin{keyword}
Bayesian inference \sep heating degree days\sep base temperature\sep
balance point temperature\sep total heat loss coefficient
\end{keyword}

\end{frontmatter}{}

<<setup, include=FALSE>>=
library(homeR)

library(dplyr)
library(ggplot2)
library(lubridate)
library(MCMCpack)
library(plyr)
library(reshape2)
library(xtable)
library(zoo)

theme_set(theme_bw(base_size = 7))

# Elsevier artwork sizes
inches_per_cm = 0.3937
single_column = 9 * inches_per_cm
one_and_half_columns = 14 * inches_per_cm
two_columns = 19 * inches_per_cm

opts_chunk$set(error = FALSE, warning = FALSE, echo = FALSE, message = FALSE,
			   results = 'hide',
               dev = "tikz",
               fig.width = single_column, fig.height = single_column, fig.align = "center")

p <- function(x) formatC(x, digits = 1, format = 'f') 
@

\global\long\def\kpre{K_{\text{pre}}}

\global\long\def\kpost{K_{\text{post}}}

\global\long\def\tb{\theta_{\text{b}}}

\global\long\def\tout{\overline{\theta_{\text{out}}}_{d}}


\section{Introduction}

Many energy conservation measures (ECMs\nomenclature[000]{ECM}{Energy Conservation Measure})
can help reduce the consumption of energy of existing buildings, but
they vary widely in effectiveness. Faced with a variety of options,
ranging from trivial (replacing light bulbs) to major (better façade
insulation), an owner will want to know which measure is likely to
yield the highest return on investment\textemdash and with what confidence.
Moreover, once the measure has been applied, the owner wants to know
how well it performs and whether their money was well spent\textemdash an
activity known as Measurement \& Verification (M\&V\nomenclature[010]{M\&V}{Measurement \& Verification}).

This is a recurring problem for large companies in Switzerland that
have publicly committed to reductions of their greenhouse gas emissions.
The majority of these emissions can be traced to large portfolios
of legacy buildings \citep{BFE2013b}, in particular to the fossil
fuels used for heating. Reducing the heating energy for legacy buildings
(while maintaining user comfort) will help such companies achieve
their objectives\textemdash provided those energy savings can be proven.
This is frequently a stumbling block for building managers with a
finite budget, who may prefer allocating resources to well-understood
(but perhaps less effective) building optimization projects.

Proving the effectiveness of any ECM is hard. Many factors influence
the energy consumption of a building, and they must be accounted for
before and after the installation of the ECM. Proper M\&V typically
involves the establishment of a ``baseline'' model of the building's
energy consumption, ideally over at least one year. The measured energy
consumption post-retrofit is then compared with the energy consumption
predicted by the baseline model, yielding the energy savings, either
in absolute terms or in relative. But in our experience, it would
appear that many M\&V projects ignore the uncertainties surrounding
the baseline model and report a point estimate for the energy savings,
giving a false sense of accuracy.

Lack of confidence in the effectiveness of ECMs hinders their adoption
\citep{Ma2012}. To convince building owners to undertake more building
retrofit projects we must address two concerns: 1) the risk that the
ECM might not be as effective as advertised, and 2) the risk that,
although effective, the benefits will turn out to be difficult to
prove. The latter is the goal of M\&V, currently perceived as ``an
inaccurate science: an engineering practice relying heavily on professional
judgement'' \citep{Xia2013}. We must show building owners that assessing
the effectiveness of ECMs can be a well-defined and well-understood
process, one that yields not just the estimated energy savings but
also their accuracy, while complying with existing international norms.

\subsection{The International Performance Measurement and Verification Protocol}

The International Performance Measurement and Verification Protocol
(IPMVP\nomenclature[020]{IPMVP}{International Performance Measurement and Verification Protocol})
\citep{evo2012} is a widely recognized framework for conducting M\&V
projects. It provides a set of guidelines and defines common terms
for such projects. Energy savings are determined by first establishing
a model of the building's baseline energy demand. After the installation,
the energy demand is measured again, resulting in a so-called reporting
period demand. Energy savings are calculated from the difference between
the baseline and reporting period demand, taking into account external
factors that influence the demand:
\begin{align*}
\text{Savings} & =\text{Baseline-period demand}\\
 & \quad\phantom{}-\text{Reporting-period demand}\\
 & \quad\phantom{}\pm\text{Adjustments}
\end{align*}
 The IPMVP leaves no doubt on the need for quantifiable uncertainties:
\begin{quote}
In order to communicate savings in a statistically valid manner, savings
need to be expressed along with their associated confidence and precision
levels. \citep[p. 88]{evo2012}
\end{quote}
Indeed the whole point of M\&V projects is to \emph{reliably} determine
energy savings. Although the definition of ``reliably'' rests ultimately
on the user of the M\&V report, the IPMVP suggests that savings, to
be statistically significant, should be at least twice the standard
error of the baseline energy consumption \citep[p. 88]{evo2012}.
But the IPMVP is silent on the methods by which the uncertainties
are to be estimated. This is left to the best judgement of the assessor.

\subsection{Recent assessments}

To see how such projects are carried out in a laboratory setting,
we performed a Scopus search for ``IPMVP'' in a document's title,
abstract or keywords, limited to publication date from 2010 to present.
This yields 37 documents, of which just 3 study the energy efficiency
of an ECM without resorting to computer simulation:
\begin{itemize}
\item The retrofit of a water cooling package unit, whose baseline consumption
from July 2012 to June 2013 was modeled as a linear combination of
occupancy, number of working days and cooling degree days. The reporting
period ran from August 2013 to July 2014, and a $t$-test determined
whether the energy savings were significant. Very different results
were obtained depending on which variables were used to model the
baseline energy consumption, and the relative uncertainty on the energy
savings ranged from 86\% to 232\% \citep{Aris2015}.
\item Two near-identical 300-seat conference rooms retrofitted with a variable-flow
air-handling unit. The energy savings were determined by simulation
and by retrofitting one room while leaving the other unchanged. Both
approaches yielded roughly 30\% energy savings on the heating coil's
consumption, but the simulation grossly underestimated the savings
on the fans' electrical consumption \citep{Ginestet2010}. 
\item A large-scale government-sponsored program offering rebates to home
owners for increasing the energy efficiency of new and existing homes
by at least 30\%. Nearly 12\,000 households participated during the
6 years of the program. The IPMVP protocol was tested on some households
that participated in 2003. The baseline was established as a linear
model in heating degree days, cooling degree days, relative humidity
and energy price on 52 households out of the 730 households that participated
in 2003. An average of 172 kWh annual energy savings was found, with
monetary annual savings ranging from -\$515 to \$530 \citep{Kaiser2010}. 
\end{itemize}
Other examples of retrofit assessments found in the literature include:
\begin{itemize}
\item \citet{Cohen1991} described an analysis of 32 retrofit projects,
ranging in size from three to 30 000 houses, in order to rank the
cost-effectiveness of different energy conservation measures. The
space heating energy was normalised to a fixed base temperature of
18.3\,\textcelsius . The project used a mix of submetered data and
utility bills.
\item A high-tech, 31\,000\,m\textsuperscript{2} campus in California
whose HVAC equipment was retrofitted. The baseline period ran from
September 2007 to August 2008, and the reporting period from May 2009
to April 2010. The energy consumption was normalised to the outdoor
temperature, and the annual electricity consumption was reduced by
3\,853\,625\,kWh, although no uncertainty was reported for this
extraordinarily precise figure \citep{Lin2015}.
\item An analysis of the electric load of 17 office buildings, modeled as
a piecewise linear function of time of week and outdoor temperature.
Cross-validation was used to estimate the uncertainty in the baseline:
the last month of baseline data was excluded from the model, and compared
with the model's prediction. The difference is an estimate of the
model's uncertainties \citep{Walter2014}.
\end{itemize}
This short review suggests that even in an academic setting, the uncertainty
on energy savings are frequently highly dependent on the model \citep{Aris2015},
assume an arbitrary base temperature for heating degree days calculation
\citep{Kaiser2010,Cohen1991}, or are ignored \citep{Ginestet2010,Lin2015}.
\citet{Walter2014} have proposed a method that is a step towards
making energy savings uncertainty estimation more reliable, but they
concede that the method is limited by the amount of data available.

In this paper we describe a method based on Bayesian data analysis,
that will yield correct uncertainties no matter how much, or how little,
data is available.

\subsection{Present study}

Swisscom, a leading Swiss telecommunications company, owns and operates
about 1300 buildings in Switzerland, of which about 950 are sales,
office, and non-production buildings. They are one of the largest
building owners in Switzerland in number of buildings. Their yearly
energy bills for their buildings is estimated at CHF 70 million. They
have publicly committed themselves to ``save double the amount of
CO\textsubscript{2} generated by {[}their{]} entire operations and
supply chain'' for themselves and their customers by 2020, and to
``increase {[}their{]} own energy efficiency by a further 35\% between
2016 and 2020'' \citep{swisscom2016}. Like many major Swiss companies,
their stock of buildings is dominated by heating systems using non-renewable
fuels. Energy conservation measures that help these buildings become
more efficient are particularly attractive. In late 2015, a pilot
study was chartered to evaluate the effectiveness of model-predictive
control for space heating.

A commercial adaptive model-predictive controller based on artificial
neural networks called NOL\textsuperscript{a} (Neurobat OnLine\textemdash analog)
\citep{neurobat2017} was selected for a building in Sargans, a Swiss
locality in the canton of St Gall. Like many buildings, the pre-installation
energy efficiency of this building was not well understood by the
building's owner, and the project plan did not allow for the measurement
of a baseline. All that was available was a record of oil tank refills,
stretching back to 2011. The poor baseline data made Bayesian methods,
which maximize the use of the available information, particularly
attractive for this project.

We first describe the test installation in section \ref{sec:Experimental-building},
followed by a review in section \ref{sec:Bayesian-energy-model} of
the Bayesian data analysis method we employed to establish the building's
baseline performance and post-installation performance. The weather,
baseline period and reporting period data will be analysed in section
\ref{sec:Data-analysis}, and inferences about the effectiveness of
the controller will be drawn in section \ref{sec:Results}.

\section{Experimental building\label{sec:Experimental-building}}

The Sargans building shown in Fig.~\ref{fig:composite} includes
four heating circuits, covering about 2740\,m\textsuperscript{2},
with heating water provided by an oil-fired boiler. The NOL\textsuperscript{a}
system was installed in March 2016 on three of the four circuits,
commonly referred to as Neubau, Büro, and Wohnung, the latter two
belonging to the old part of the building (Altbau). The fourth circuit
was deemed not to require optimisation, as the zone in question is
kept relatively cool. The total surface covered by NOL\textsuperscript{a}
is about 1840\,m\textsuperscript{2}.

The oil-fired boiler draws its fuel from two tanks and provides the
heating water to all heating circuits. The levels in the tanks are
recorded at irregular intervals, such as when a tank is refilled.
The domestic hot water is provided by an independent electrical circuit.

The NOL\textsuperscript{a} system is a model-predictive controller
that regularly computes an optimal water supply temperature. It belongs
to the ECM category of ``Energy efficient equipment and low energy
technologies'', a form of demand side management \citep{Ma2012}.
The optimal temperature cannot be communicated directly to most legacy
heating controllers; instead, the NOL\textsuperscript{a} system controls
the flow temperature indirectly by shifting the outdoor temperature
measured by the existing heating controllers. Thus, the boiler provides
heating water for each circuit at just the right temperature for that
circuit. The details of the NOL\textsuperscript{a} algorithms are
beyond the scope of this article but can be found elsewhere \citep{Bauer98,Zimmermann1985,Morel2001161,Krauss200863,Bichsel2000,NoAuthor1998,Lindelof2015}. 

The sensors attached to the NOL\textsuperscript{a} system (including
an oil meter) are automatically sampled several times per hour and
stored in a database. The data is used for monitoring, preventive
maintenance, and offline analysis.

\begin{figure}
\begin{centering}
\includegraphics[width=0.8\columnwidth]{img/sargans_composite}
\par\end{centering}
\caption{Aerial (top left) and side views of the Altbau (bottom) and Neubau
(right) parts of the Sargans building. The Büro and Wohnung circuits
belong to the Altbau part.}

\label{fig:composite}
\end{figure}


\section{Estimating the building's energy efficiency\label{sec:Bayesian-energy-model}}

We need to establish the building's energy efficiency before the installation
(from oil refill readouts) and after (from oil meter readouts). We
will describe a fully Bayesian approach to do so, because to the best
of our knowledge, only Bayesian methods maximize the information contained
in the data, and perhaps more importantly, only Bayesian methods seem
to us free from arbitrary decisions.

For example, most linear regression problems minimize the squared
error between the observed and the fitted data. But why do we minimize
the squared error, and not, say, the absolue value? Bayesian linear
regression provides an answer to this question, and can also help
decide when the absolute error is more appropriate.

When it comes to estimating a building's base temperature, the performance
line method of \citet{Day2003} is frequently used when daily data
is not available. The method consists in plotting the energy against
the degree-days for a given base temperature, and fitting a second
order polynomial. The base temperature is then adjusted until the
second order coefficient vanishes. This method yields good results,
but this choice of finding a base temperature such that the relationship
between energy and degree-days becomes linear seems to us, again,
rather arbitrary.

We have also seen practitioners use variations of the performance
line method where the coefficient of determination $R^{2}$ is maximized,
where the intercept vanishes, or where the sum of unweighted squared
residuals is minimized. It would seem to us that the best alternative
to a fully Bayesian approach is a nonlinear regression, where we find
the set of parameters that minimizes the \emph{weighted} squared residuals.
This is the approach with which we will compare our fully Bayesian
one.

Both approaches require a model for the heating demand of the building;
that model happens to be the same for both approaches. We describe
that model first, and then show how both approaches deal with the
problem.

\subsection{Heating energy model}

The energy consumed by a building is rarely constant but varies over
time due to so-called routine factors (expected to vary, such as the
climate) and non-routine factors (normally constant, such as the indoor
temperature's set point or the activity inside the building). These
factors must be accounted for when assessing the effectiveness of
an ECM. This is normally done by establishing a model for the energy
use before and after the installation of the ECM, as we do here.

Under normal conditions, when the indoor temperature follows a desired
set point, the daily heating demand of a building will balance the
heat losses. The heat losses on a given day $d$ will, intuitively,
be larger on colder days than on warmer days. Some days will beso
warm that no heating is required, with all heat losses being compensated
by the sun and other free gains; the outdoor temperature threshold
above which this happens, the building's \emph{base temperature} $\tb$,
is usually taken to be equal to the indoor temperature set point up
to a constant offset. We should also allow for day-to-day random fluctuations
in the heating demand, which we will model by Gaussian noise $\mathcal{N}(0,\sigma^{2})$
\nomenclature[090]{$\mathcal{N}(0,\sigma^{2})$}{Gaussian white noise of mean 0 and variance $\sigma^2$}of
mean 0 and whose variance $\sigma^{2}$ will have to be estimated.

Putting it all together, the daily losses $Q_{d}$\nomenclature[030]{$Q_{d}$}{energy demand on day $d$}
on a day $d$ is the sum of something proportional to the positive
difference \nomenclature[100]{$(.)^{+}$}{positive part}between the
average outdoor temperature $\tout$ \nomenclature[070]{$\tout$}{mean outdoor temperature on day $d$}
and the building's base temperature $\tb$, and random noise: 
\begin{equation}
Q_{d}=K\times(\tb-\tout)^{+}+\mathcal{N}(0,\sigma^{2}),
\end{equation}
where the constant of proportionality $K$\nomenclature[050]{$K$}{total heat loss coefficient},
called the building's \emph{total heat loss coefficient}, is the quantity
of extra heat required per day to maintain indoor comfort for each
extra degree of cold. We agreed with the customer that the effectiveness
of the new control system would be uniquerely defined by changes to
$K$, since the base temperature $\theta_{\text{b}}$ might change
if the indoor temperature set point is not the same before and after
the installation.

Over a period $p$ made up of $n_{p}$ \nomenclature[045]{$n_{p}$}{number of days in period $p$}days,
the total heating load \nomenclature[040]{$Q_{p}$}{energy demand during reporting period $p$}will
be 
\begin{equation}
Q_{p}=\sum_{d\in p}Q_{d}=K\times DD_{p}+\mathcal{N}(0,n_{p}\sigma^{2}),\label{eq:Qp}
\end{equation}
where $DD_{p}=\sum_{d\in p}(\tb-\tout)^{+}$ \nomenclature[110]{$DD_{p}$}{heating degree days during period $p$}is
the number of \emph{degree days at base temperature $\tb$} during
that period. The load $Q_{p}$ and the period duration $n_{p}$ are
directly read from utility bills or energy meter readouts, while $DD_{p}$
must be calculated from historic weather data and the building's estimated
base temperature.

Our task is to estimate the total heat loss coefficient $K$, the
base temperature $\tb$, and the daily fluctuations $\sigma$ from
the data. None of them can be estimated independently of the others;
underestimating $\tb$ will lead to an overestimated $K$ and vice-versa.
This is why one cannot use a ``one size fits all'' base temperature,
as currently recommended by building regulations and policies. This
was conclusively shown by an analysis of four years of half-hourly
gas meter data on 119 buildings by \citet{Meng2017}, who found base
temperatures ranging from 11.6\,\textcelsius{} to 20.5\,\textcelsius ,
while the ``standard'' base temperature in the UK is 15.5\,\textcelsius{}
\citep{CTG075}.

\subsection{Bayesian estimation}

The set of utility bills (or energy meters readouts) $\{Q_{p},n_{p}\}$
constitutes the data we have at hand, while Eq.~\eqref{eq:Qp} is
a probability model from which that data is drawn. Bayesian inference
consists in finding the parameters of that probability model that
are the most consistent with the observed data, yielding probability
distribution functions of these parameters \citep{Gelman2013}.

Letting $D$ \nomenclature[120]{$D$}{set of energy consumption and historic weather data}stand
for the set of reporting periods (for example, a set of monthly gas
utility bills, or a list of oil tank level readouts) and historic
weather data, Bayesian inference consists in establishing the probability
density function for the parameters $\{K,\theta_{\text{b}},\sigma\}$
conditioned on the information $D$, noted as $p(\{K,\theta_{\text{b}},\sigma\}\mid D)$.
We will use the method proposed by one of the authors \citep{Lindelof2016}
and implemented in a package for the R programming environment \citep{homeR}.
Unlike that prior work, where the focus was on the determination of
a building's base temperature, here we will be more interested in
the changes to the building's heat loss coefficient $K$.

We assume that installing an ECM such as the NOL\textsuperscript{a}
will alter the building's total heat loss coefficient by a factor
$\rho$\nomenclature[130]{$\rho$}{factor by which the total heat loss coefficient has changed},
and also possibly shift the base temperature if the indoor temperature's
set point is not exactly identical before and after the installation:
\[
K_{\mathrm{pre}}\rightarrow K_{\mathrm{post}}=\rho\times K_{\mathrm{pre}}
\]
\[
\theta_{\text{b, pre}}\rightarrow\theta_{\text{b, post}}=\theta_{\text{b, pre}}+\Delta\tb
\]
A shift in the building's base temperature $\theta_{\text{b}}$ was
considered as unavoidable, since very little was known about the normal
indoor temperature's set point before the retrofit. It was therefore
agreed that the effectiveness of the ECM would be quantified by the
ratio $\rho$ between the pre- and post-installation heat loss coefficients.
The lower $\rho$ is, the more effective is the new control system.
The relative energy savings in percent (ignoring changes to $\tb$)
are then given by $100\times(1-\rho)$.

Strict Bayesians would now write a full probability model involving
all the pre- and post-installation parameters, work out the joint
posterior probability density function, draw samples from that function
and make inferences. That would be correct, but the problem can be
considerably simplified by noting that the pre- and post-installation
parameters are conditionally independent; the pre-retrofit heating
loss coefficient $K_{\text{pre}}$ is independent from its post-retrofit
counterpart $K_{\text{post}}$, and the same holds for the base temperature
$\theta_{\text{b}}$. Furthermore, the likelihood of the pre-retrofit
data $D_{\text{pre}}$ depends only on the pre-retrofit parameters,
and similarly for the post-retrofit data $D_{\text{post}}$. So we
are effectively dealing with two independent experiments: one before
the installation, and one after. The pre- and post-retrofit parameters'
probability distribution functions can, without loss of information,
be derived independently of each others.

(One could argue that the measurement noise $\sigma$ should \emph{not}
be considered as independent; in fact, it would be reasonable to consider
it as the same before and after the retrofit. We would normally agree
with that; but $\sigma$ expresses not only the daily inherent variability
in energy consumption of the building: it also includes measurement
errors. Since the oil consumption has been measured with two completely
different methods before and after the retrofit, we treat $\sigma_{\text{pre}}$
and $\sigma_{\text{post}}$ as two independent parameters.)

Putting it together formally, the task consists in establishing $p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}},K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D)$
where $D$ now stands for the union of the pre- and post-installation
data $D_{\text{pre}}$ and $D_{\text{post}}$. Since we assume conditional
independence between the parameters before and after the retrofit,
we have
\begin{align*}
p(\{K_{\text{pre}},\theta_{\text{b,pre}}, & \sigma_{\text{pre}},K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D)\\
\begin{split}=\phantom{} & p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}}\}\mid D)\\
 & \times p(\{K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D)
\end{split}
\\
\begin{split}=\phantom{} & p(\{K_{\text{pre}},\theta_{\text{b,pre}},\sigma_{\text{pre}}\}\mid D_{\text{pre}})\\
 & \times p(\{K_{\text{post}},\theta_{\text{b,post}},\sigma_{\text{post}}\}\mid D_{\text{post}})
\end{split}
\end{align*}
where each term in the product on the right-hand side can be computed
by the method proposed by \citet{Lindelof2016}. Once we have the
pdf on the left-hand side of the equation, inferences about $\rho=K_{\text{post}}/K_{\text{pre}}$
can be made by drawing random pairs of $\{\kpre,\kpost\}$ values
from this pdf and looking at the distribution of $\rho$.

\subsection{Nonlinear regression}

In nonlinear regression we search for the set of parameters $\{K,\tb,\sigma\}$
that minimizes the sum of weighted squared residuals
\[
\sum_{p}(Q_{p}-K\times DD_{p})^{2}/n_{p}(?).
\]
 This can be handled by off-the-shelf funciton optimization routines,
which will find the ``best'' estimate of the $\{K,\tb,\sigma\}$
parameters. Most solvers will also evaluate the Hessian of the objective
function around its minimum, approximating it with a quadratic function
of the parameters, and use the curvature of that approximation to
estimate the uncertainty on the parameters.

This is indeed what was done by \citet{Lindelof2016}, where the log-likelihood
was to be maximized. In fact, findint the set of parameters that maximizes
the posterior probability density function is in fact itself a nonlinear
regression problem. Bayesian methods, however, yield (through the
posteriod pdf) more information than a single pdf maximum. And as
we will see, the uncertainty on the estimated parameters will be different.

\section{Data analysis\label{sec:Data-analysis}}

The International Performance Measurement and Verification Protocol
(IPMVP) requires an auditor to establish the performance of the building
before the installation of the ECM (the \emph{baseline} period) and
after (the \emph{reporting} period). Unlike traditional IPMVP projects,
this pilot building is challenging because daily oil consumption readouts
from an oil meter were available only after the installation of the
NOL\textsuperscript{a}. The energy savings must therefore be derived
from different sources: manual oil level readouts before the installation,
and automated daily oil readouts after.

\subsection{Weather data}

The historic weather data (going back to 2011) is obtained from \citet{meteosuisse2016},
who provides a file with average daily temperatures measured in Bad
Ragaz (about 6\,km from Sargans) and Vaduz (about 10\,km). The relative
positions of the pilot building in Sargans and of the Bad Ragaz and
Vaduz weather stations are shown in the map in Fig.~\ref{fig:stations}.
The Bad Ragaz data is shown against time in Fig.~\ref{fig:ClimatePlot}.
A scatterplot of the temperatures from Bad Ragaz against those from
Vaduz is shown in Fig.~\ref{fig:ClimateScatterPlot}. Since there
are no obvious differences between the two weather stations we use
from now on the data from Bad Ragaz. Sargans lies 483\,m above sea
level, Bad Ragaz 496\,m, so we do not adjust the outdoor temperature
for altitude.

\begin{figure}
\begin{centering}
\includegraphics[width=1\columnwidth]{img/map}
\par\end{centering}
\caption{Sargans region, including the Bad Ragaz and Vaduz weather stations}
\label{fig:stations}
\end{figure}

<<>>=
climate2 <- read.table("data/RAD_VAD.txt",
  skip = 10,
  na.strings = "32767",
  colClasses = c(V1 = "factor"))
climate2 <- transform(climate2, Date = as.Date(ymd(paste(V2, V3, V4, sep = "-"))))
climate2 <- subset(climate2, select = c(1, 8, 7))
names(climate2) <- c("Station", "Date", "Temperature")
levels(climate2$Station) <- c("Bad Ragaz", "Vaduz")
climate <- climate2
climate.wide <- dcast(climate, Date ~ Station) 
@

<<ClimatePlot, fig.cap="Historic outdoor temperatures measured at Bad Ragaz.", fig.width=3.5, fig.height=2>>=

ggplot(subset(climate, Station=='Bad Ragaz'), aes(Date, Temperature)) +
	geom_line() +
	xlim(as.Date("2010-12-20"), as.Date("2016-04-30")) +
    ylab("Temperature (\\textcelsius)")
@

<<ClimateScatterPlot, fig.cap="Comparison between Bad Ragaz and Vaduz temperatures.", fig.width=3>>=
ggplot(climate.wide, aes(`Bad Ragaz`, Vaduz)) + geom_point(alpha = 0.5, size = 1) + coord_fixed() 
@

\subsection{Baseline oil consumption}

The historic oil consumption data consists in a sheet of paper used
to log the readouts of the oil levels in the boiler's tanks. A copy
of the original paper is shown in Fig.~\ref{fig:readouts} in the
Appendix. A transcribed version is shown in Table~\ref{tab:oilReadouts}.

<<results='asis'>>=

oilReadingsDf <- read.table(text = "
Date        Tank1  Tank2
2011-02-03   7500  13300
2011-05-25   5500  13000
2011-10-25   4000  13000
2011-11-25  10700     NA
2012-02-23  10500   3300
2012-04-10  10000    500
2012-05-02     NA  11100
2012-05-27   8000  10500
2013-01-15  10000  10300
2013-03-06  10000   5200
2013-06-17  10000   5000
2013-08-15   9500      0
2013-08-15  13450  12500
2013-11-27  13437   8800
2014-07-25   9500    500
2014-09-24   9000    500
2014-09-24   9000  12500
2014-11-18   7000  12500
2014-11-18   9100  12500
2014-12-03   7400  12500
2015-02-10     NA  12400
2015-03-25      0   7500
2015-06-10  13200  10000
2015-12-15  13200   3500
2016-03-08   8500     NA
",
                          header = TRUE,
                          colClasses = c(Date = "Date"))
oilReadingsDf <- transform(oilReadingsDf, Total = Tank1 + Tank2)
oilReadings <- zoo(oilReadingsDf[,-1], order.by = oilReadingsDf$Date)
betweenReadings <- (function(x) diff(x) / diff(range(x))) (as.numeric(oilReadingsDf$Date))

# call to as.character is a workaround for https://r-forge.r-project.org/tracker/?func=detail&group_id=1228&aid=6465&atid=4864
print(xtable(transform(oilReadingsDf, Date = as.character(Date)),
			 caption = "Transcribed oil level readouts.",
			 label = "tab:oilReadouts"),
      booktabs = TRUE,
      include.rownames = FALSE,
      add.to.row = list(pos = list(4, 8, 14, 20, 24), command = rep('\\\\', 5)))
@

There are log entries (for example on 2 May 2012) when one tank was
filled without recording its level before the refill. In such instances
it is impossible to know how much oil was used during the preceding
period. We therefore restrict this data to the 12 periods during which
neither tank level increased, for example between 2011-02-03 and 2011-05-25
(2300\,L of oil) but not between 2011-10-25 and 2011-11-25 (no readout
for the second tank) nor between 2015-03-25 and 2015-06-10 (both tanks
increased).

Each period is matched with its historic weather data, yielding for
each period a list of mean daily outdoor temperatures with one datum
for each day of the period. We obtain the data shown in Table \ref{tab:oilperiods}.

<<>>=
oilConsumptionPeriods <- data.frame(from = head(index(oilReadings), -1),
                                    to = tail(index(oilReadings), -1),
                                    oil = - diff(as.numeric(oilReadings$Total)))
# Find periods during which neither tank was filled
oilConsumptionPeriods <- with(oilReadings,
                              oilConsumptionPeriods[diff(as.numeric(Tank1)) <= 0 &
                                                      diff(as.numeric(Tank2)) <= 0, ])
oilConsumptionPeriods <- na.omit(oilConsumptionPeriods)
oilConsumptionPeriods <- transform(oilConsumptionPeriods,
                                   nDays = to - from)
@

<<results='asis'>>=

climate.zoo <- zoo(subset(climate.wide, select = -Date), climate.wide$Date)
tempInInterval <- function(climate, from, to) {
  as.numeric(window(climate, start = from, end = to))
}
oilConsumptionPeriods <-
  adply(oilConsumptionPeriods,
        .margin = 1,
        .fun = mutate,
        meanTemps = I(list(tempInInterval(climate.zoo$`Bad Ragaz`, from, to))))
oilConsumptionPeriods$meanTemp <- sapply(oilConsumptionPeriods$meanTemps, mean, na.rm = TRUE)
# Days with missing data are imputed with mean temperature of their period
oilConsumptionPeriods$meanTemps <- lapply(oilConsumptionPeriods$meanTemps,
                                          function(x) {
                                            x[is.na(x)] <- mean(x, na.rm = TRUE)
                                            x})
oilConsumptionPeriodsTable <- 
  oilConsumptionPeriods %>%
    dplyr::select(-meanTemps) %>%
    dplyr::mutate(from = as.character(from)) %>%
    dplyr::mutate(to = as.character(to)) %>%
    dplyr::mutate(meanCnsmptn = oil / as.numeric(nDays)) %>%
    dplyr::select(from, to, nDays, oil, meanCnsmptn, meanTemp) %>%
    dplyr::rename("{From}" = from, "{To}" = to, "{Days}" = nDays, "{Oil (L)}" = oil, "{Avg. daily cons. (L)}" = meanCnsmptn, "{Avg. temp. (\\textcelsius)}" = meanTemp) %>%
    xtable(caption = "Usable pre-retrofit consumption periods. The building's average energy demand is about 207\\,720\\,kWh/a according to the building manager, which would be about 56\\,L/d of oil on average assuming a heat content of 10.08\\,kWh/L.", label = "tab:oilperiods", digits = c(0, 0, 0, 0, 0, 1, 1), align = c("l", "l", "l", "S[table-format=5]", "S[table-format=3]", "S", "S"))
print(oilConsumptionPeriodsTable,
  booktabs = TRUE,
  floating.environment = "table*",
  width = "\\hsize",
  sanitize.colnames.function = identity,
  include.rownames = FALSE)
@

<<>>=
load("data/readings.RData.gz")
sargans <- do.call(merge, readings)
@

<<>>=
dailyOil <- aggregate(readings$sargans003$Oil1_volume1, function(x) floor_date(x, "day"), function(x) diff(range(x)))
index(dailyOil) <- as.Date(index(dailyOil), tz = "CET")
dailyOil <- merge(dailyOil, na.omit(climate.zoo$`Bad Ragaz`), all = FALSE)
names(dailyOil) <- c("Oil", "MeanTemp")
@

<<>>=
goodPeriods <- with(oilConsumptionPeriods,
               	data.frame(Oil = oil,
                      		DailyMeans = I(meanTemps),
                      		When = "PRE",
							  Good = TRUE))
goodPeriods$Good[c(5, 6)] <- FALSE

goodPeriods <- with(window(dailyOil, start = "2016-04-01"),
                	rbind(goodPeriods,
                  		data.frame(Oil = Oil,
									 DailyMeans = MeanTemp,
									 When = "POST",
									 Good = TRUE)))
goodPeriods$Good[rownames(goodPeriods) == "2016-04-06"] <- FALSE
@

<<>>=
fit.before <- bhm(Oil ~ DailyMeans, subset(goodPeriods, When == "PRE" & Good), baseLoad = 0)
baseTempPre <- coef(fit.before)['tb']
deltaBaseTempPre <- sqrt(diag(vcov(fit.before)))['tb']
Kpre <- coef(fit.before)['K']
deltaKpre <- sqrt(diag(vcov(fit.before)))['K']
sigmaPre <- coef(fit.before)['sigma']

fit.after <- bhm(Oil ~ DailyMeans, subset(goodPeriods, When == "POST" & Good), baseLoad = 0)
baseTempPost <- coef(fit.after)['tb']
deltaBaseTempPost <- sqrt(diag(vcov(fit.after)))['tb']
Kpost <- coef(fit.after)['K']
deltaKpost <- sqrt(diag(vcov(fit.after)))['K']
sigmaPost <- coef(fit.after)['sigma']
@

<<>>=
epochEnergy <- function(periods) {
  function(K, tb) homeR:::epochEnergy(K, tb, DHW = 0, periods$DailyMeans)
}
epochEnergyPre <- epochEnergy(subset(goodPeriods, When == "PRE" & Good))
OilPre <- subset(goodPeriods, When == "PRE" & Good)$Oil
epochEnergyPost <- epochEnergy(subset(goodPeriods, When == "POST" & Good))
OilPost <- subset(goodPeriods, When == "POST" & Good)$Oil

nlsfit.before <- nls(OilPre~epochEnergyPre(K,tb), start = list(K = 3, tb = 20))
nlsfit.after <- nls(OilPost~epochEnergyPost(K,tb), start = list(K = 3, tb = 20))

coefs.nls.before <- nlsfit.before %>% summary %>% coef
coefs.nls.after <- nlsfit.after %>% summary %>% coef

Kpre.nls <- coefs.nls.before['K', 'Estimate']
deltaKpre.nls <- coefs.nls.before['K', 'Std. Error']
baseTempPre.nls <- coefs.nls.before['tb', 'Estimate']
deltaBaseTempPre.nls <- coefs.nls.before['tb', 'Std. Error']

Kpost.nls <- coefs.nls.after['K', 'Estimate']
deltaKpost.nls <- coefs.nls.after['K', 'Std. Error']
baseTempPost.nls <- coefs.nls.after['tb', 'Estimate']
deltaBaseTempPost.nls <- coefs.nls.after['tb', 'Std. Error']
@

Note that two records in the oil readouts are probably erroneous and
should be excluded from the analysis: 
\begin{enumerate}
\item From 2013-03-06 to 2013-06-17 (103 days): 200 L, or about 2 L per
day
\item From 2013-06-17 to 2013-08-15 (59 days): 5500 L, or about 100 L per
day during summer
\end{enumerate}
The building's base temperature and heat loss coefficient are estimated
from this data. The Bayesian approach yields 
\[
\theta_{\text{b,pre}}=\Sexpr{p(baseTempPre)}\pm\Sexpr{p(deltaBaseTempPre)}\thinspace\text{\textcelsius},\quad K_{\mathrm{pre}}=\Sexpr{p(Kpre)}\pm\Sexpr{p(deltaKpre)}\thinspace\text{L/Kd},
\]
 while the nonlinear regression yields
\[
\theta_{\text{b,pre}}=\Sexpr{p(baseTempPre.nls)}\pm\Sexpr{p(deltaBaseTempPre.nls)}\thinspace\text{\textcelsius},\quad K_{\mathrm{pre}}=\Sexpr{p(Kpre.nls)}\pm\Sexpr{p(deltaKpre.nls)}\thinspace\text{L/Kd}.
\]
 Both approaches yield comparable results, but there is one important
difference: the Bayesian approach provides a posterior pdf for each
parameter, which in turn makes it possible to compute a posterior
pdf for quantities derived from these parameters. In particular, we
will later have to calculate the pdf of $\kpost/\kpre$; this cannot
be done easily with the point estimates provided by the nonlinear
regression.

Now that we have the building's base temperature, we can validate
it by calculating the number of degree days for each oil consumption
period and plotting the oil consumed during each period against the
degree days of that period. If the base temperature is correct, we
should obtain points lying on a straight line that goes through the
origin. We show this in Fig.~\ref{fig:OilVsDD}, where for comparison
we do the same with degree days calculated with nonlinear regression
and using different official standards \citep{ashrae2013,CTG075}
. The Bayesian method yields the best results. The relationship between
the oil consumption and the degree days using the estimated base temperature
is satisfactorily linear, with the exception of the two outliers identified
above, and possibly a third point with 2300 liters of oil for about
750 degree days. 

<<OilVsDD, fig.cap="Oil consumption vs heating degree days, calculated with different base temperatures as follows. Bayesian: calculated from the data as described in the main text; ASHRAE: 65\\,\\textdegree{}F (18.3\\,\\textcelsius) as recommended by the ASHRAE Handbook \\citep{ashrae2013}; SIA 380:2015: 12\\,\\textcelsius, the standard used in Switzerland; Carbon Trust: 15.5\\,\\textcelsius, the standard used in the UK \\citep{CTG075}; SIA 381/3: a retired Swiss norm, where the base temperature is 20\\,\\textcelsius{} but only for those days whose average temperature is below 12\\,\\textcelsius. Unfilled circles indicate the two records that have been excluded from the analysis. The heat loss coefficient $K$ is given in L/K. The Bayesian base temperature yields the highest coefficient of determination $R^2$, suggesting that it fits the data best.", fig.width=one_and_half_columns, fig.height=4, fig.env="figure*">>=

pos <- function(x) pmax(0, x)
DD <- function(dailyTemps, base) sum(pos(base - dailyTemps))
before.dd <- subset(goodPeriods, When == "PRE")
before.dd$Bayesian <- laply(before.dd$DailyMeans, DD, baseTempPre)
before.dd$ASHRAE <- laply(before.dd$DailyMeans, DD, 18.3)
before.dd[["SIA 380:2015"]] <- laply(before.dd$DailyMeans, DD, 12)
before.dd[["Carbon Trust"]] <- laply(before.dd$DailyMeans, DD, 15.5)
before.dd[["SIA 381/3"]] <- laply(before.dd$DailyMeans, function(x) sum(ifelse(x < 12, 20 - x, 0)))
before.dd.long <- melt(before.dd, 
	id.vars = c("Oil", "Good"), 
	measure.vars = c("Bayesian", "ASHRAE", "SIA 380:2015", "Carbon Trust", "SIA 381/3"),
	variable.name = "Base",
    value.name = "Degree days")
before.rsq <- before.dd.long %>%
  dplyr::filter(Good) %>%
  dplyr::group_by(Base) %>%
  dplyr::do(model = lm(Oil ~ `Degree days`, data = .)) %>%
  dplyr::mutate(rsq = summary(model)$r.squared,
         K = coef(model)[2]) %>%
  dplyr::select(-model)
before.rsq$label <- format(before.rsq$rsq, di = 3)
before.rsq$Klabel <- format(before.rsq$K, di = 2)

ggplot(before.dd.long, aes(`Degree days`, Oil, fill = Good)) +
	geom_point(shape = 21) +
    scale_fill_manual(values = c("white", "black")) +
	facet_wrap(~ Base) +
	geom_smooth(method = "lm", data = subset(before.dd.long, Good), formula = y ~ x, se = FALSE, color = "black") + 
	geom_text(data = before.rsq, aes(1100, 2500, label = paste("italic(K)=='", Klabel, "'"), hjust = 0), parse = TRUE, size = rel(3), inherit.aes = FALSE) +
  geom_text(data = before.rsq, aes(1100, 1000, label = paste("italic(R)^2=='", label, "'"), hjust = 0), parse = TRUE, size = rel(3), inherit.aes = FALSE) +
	ylab("Oil (L)") +
    xlab("Degree days (Kd)") +
    theme(legend.position = "none", panel.spacing = unit(0, "lines"), aspect.ratio = 1)
@


\subsection{Reporting period}

The new control system included an oil counter that could be read
out automatically. With this data we could correlate the oil consumption
with the outdoor temperature on a daily basis, instead of having to
wait until the next oil tank refill. That relationship is shown in
Fig.~\ref{fig:Signature}. 

<<Signature, fig.cap="Daily oil consumption vs daily average outdoor temperatures. A linear fit is shown with its confidence bands. A second order coefficient was not statistically significant ($p=0.198$).">>=
signature <- qplot(as.numeric(DailyMeans), 
	Oil,
	data = subset(goodPeriods, When == "POST"),
	xlab = "Mean outdoor temperature (\\textcelsius)",
	ylab = "Oil (L)") +
	geom_smooth(method = "lm", color = "black")
signature
@

Each point in this plot represents one day between 1 April 2016, when
a mislabeling of the existing heating system was identified and corrected,
and 16 May 2016, just before the end of the heating season. The post-installation
total heat loss coefficient $K_{\mathrm{post}}$ is the slope of the
linear regression through these points, since each point represents
one day of oil consumption and they all are lower than the base temperature.
The Bayesian approach yields
\[
\theta_{\text{b,post}}=\Sexpr{p(baseTempPost)}\pm\Sexpr{p(deltaBaseTempPost)}\thinspace\text{\textcelsius}\quad K_{\mathrm{post}}=\Sexpr{p(Kpost)}\pm\Sexpr{p(deltaKpost)}\,\text{L/Kd},
\]
 while the nonlinear regression yields
\[
\theta_{\text{b,post}}=\Sexpr{p(baseTempPost.nls)}\pm\Sexpr{p(deltaBaseTempPost.nls)}\thinspace\text{\textcelsius}\quad K_{\mathrm{post}}=\Sexpr{p(Kpost.nls)}\pm\Sexpr{p(deltaKpost.nls)}\,\text{L/Kd}.
\]
 Again, both approaches are practically equivalent, and they both
find a post-installation heat loss coefficient about 30\% smaller
than before the installation. Notice also how daily meter readouts
improve the precision of the parameter estimation compared with historic
oil fill records.

\section{Results\label{sec:Results}}

<<cache=TRUE>>=
metropfun <- function(x, logPBefore, logPAfter)
  logPBefore(x[1], x[2], 0, x[3]) + logPAfter(x[4], x[5], 0, x[6])
m <- MCMCmetrop1R(metropfun, c(Kpre, baseTempPre, sigmaPre, Kpost, baseTempPost, sigmaPost), seed = 1345, tune = 1.3, logPBefore = fit.before$logPosterior, logPAfter = fit.after$logPosterior)
m <- cbind(m, 1 - m[, 4] / m[, 1])
colnames(m) <- c("Kpre", "baseTempPre", "sigmaPre", "Kpost", "baseTempPost", "sigmaPost", "savings")
@

<<>>=
HDIofMCMC <- function(samples, credMass = 0.95) {
  sortedSamples <- sort(samples)
  nInCI <- ceiling(credMass * length(samples))
  nCandidateCI <- length(samples) - nInCI
  CIWidths <- rep(0, nCandidateCI)
  for (i in 1:nCandidateCI) {
    CIWidths[i] <- sortedSamples[i + nInCI] - sortedSamples[i]
  }
  HDImin <- sortedSamples[which.min(CIWidths)]
  HDImax <- sortedSamples[which.min(CIWidths) + nInCI]
  c(HDImin, HDImax)
}
@

<<>>=
rhoCI <- HDIofMCMC(m[, 'Kpost'] / m[, 'Kpre'], 0.67)
rho <- mean(rhoCI)
Drho <- diff(rhoCI) / 2
@

<<>>=
rhocdf <- ecdf(m[, 'savings'])
savingsPercent <- 100 * (1 - rho)
savingsError <- 100 * Drho
@

<<>>=
drationorm <- function (x, meanx = 0, sdx = 1, meany = 0, sdy = 1) {
    a <- function(x) sqrt(x^2/sdx^2 + 1/sdy^2)
    b <- function(x) meanx / sdx^2 * x + meany / sdy^2
    c <- meanx^2 / sdx^2 + meany^2 / sdy^2
    d <- function(x) exp((b(x)^2 - c * a(x)^2) / (2 * a(x)^2))
    b(x) * d(x) / a(x)^3 * 1 / (sqrt(2 * pi) * sdx * sdy) * (pnorm(b(x) / a(x)) - pnorm(- b(x) / a(x))) + 1 / (a(x)^2 * pi * sdx * sdy) * exp(-c^2/2)
}
@

The effect on the building's heat loss coefficient (and its uncertainty),
defined as $\rho=K/K_{\mathrm{pre}}$, can now be evaluated. From
a Bayesian point of view, $\rho$ is a function of two random variables
$\kpre$ and $\kpost$ and we need its probability distribution function.
This can be estimated from random draws from the joint pdfs of $\kpre$
and $\kpost$, calculating $\rho$ (or rather, $1-\rho$), and evaluating
values of interest such as the mean value, standard deviation, and
so on. 

A histogram of the $1-\rho$ values resulting from 20\,000 draws
is shown in Fig.~\ref{fig:RhoDensity}. The majority of that histogram
is positive, indicating a decrease in the heat loss coefficient. Any
statement about the energy savings can now be made with its associated
confidence. For example, 75\% of the mass of this histogram lies to
the right of 0.14; this can be reported to decision makers by saying
that the heat loss coefficient has been reduced by at least 14\% with
75\% confidence. 

But this distribution clearly does not follow a normal distribution,
so it would be misleading to merely report the distribution's mean
and standard deviation. The `best' estimate of the effect is obtained
instead by finding the narrowest range of $\rho$ values such that
they encompass $N$\% of the mass of the histogram, also known as
the $N$\% credible interval, for any desired $N$. Since one standard
error of a normal distribution corresponds to a 67\% credible interval,
we agreed with the building owner that the uncertainty on the effect
should be reported with the same $N$. We obtain:
\[
\text{Reduction of heat losses (\%)}=\Sexpr{p(savingsPercent)}\pm\Sexpr{p(savingsError)},
\]
where the $\pm$ sign is understood to represent the 67\% credible
interval.

What would we have done differently if we had estimated the building
parameters from nonlinear regression? We have point estimates of the
total heat loss coefficients before and after the installation, together
with their standard error. But we don't know their distribution (since
a nonlinear regression does not yield pdfs), so we are forced to assume
Gaussian distributions. The ratio of two Gaussian random variables
has a closed form (if one is willing to accept the error function
as an elementary function), and the probability density computed by
this closed form, using the moments calculated by the nonlinear regression,
is shown as a solid line on Fig.~\ref{fig:RhoDensity}. If the two
approaches agreed, the solid line would roughly go through the top
center of each bar of the histogram. Here they disagree somewhat:
the non-linear regression is slightly shifted to the left, towards
negative values. The non-linear regression approach would therefore
tend to underestimate the effect on the heat loss coefficient.

An uncertainty of $\Sexpr{p(savingsError)}$ percentage points may
sound large and it is tempting to try and reduce that error by letting
the experiment run longer. But doing so will only reduce the error
on the post-installation heat loss coefficient $K_{\text{post}}$;
there is nothing we can do about the error on the pre-installation
heat loss coefficient $K_{\text{pre}}$, which dominates the total
error. The absolute error on $\rho$ has a lower limit given by the
relative error on $K_{\text{pre}}$: $\Delta\rho\geq\rho\times\Delta K_{\text{pre}}/K_{\text{pre}}$.
In our case, $\rho=\Sexpr{p(rho)}$, $\Delta K_{\text{pre}}=\Sexpr{p(sd(m[,'Kpre']))}$,
$K_{\text{pre}}=\Sexpr{p(mean(m[,'Kpre']))}$ and therefore $\Delta\rho\geq\Sexpr{p(mean(m[,'Kpost']/m[,'Kpre'])*sd(m[,'Kpre'])/mean(m[,'Kpre']))}$,
very close to the current uncertainty of $\Sexpr{p(savingsError)}$
percentage points. After $\Sexpr{nrow(subset(goodPeriods,When=='POST'))}$
days, our accuracy is almost as good as it will ever get. 

<<RhoDensity, fig.cap="Probability density distribution of the heat loss reduction $1-\\rho$.">>=
ggplot(data.frame(x = 100 * m[, 'savings']), aes(x)) +
  geom_histogram(aes(y = ..density..)) +
  xlab("Heat losses reduction (\\%)") +
  ylab("Probability density") +
  xlim(-100, 100) +
  stat_function(fun = function(x, ...) drationorm(1 - x / 100, ...) / 100, args = list(meanx = Kpost, sdx = deltaKpost, meany = Kpre, sdy = deltaKpre))
@

The magnitude of the effect is less than twice its uncertainty, so
a strict interpretation of the IPMVP text would deem it not statistically
significant. But Fig.~\ref{fig:RhoDensity} makes it clear that the
effect is more likely to be positive than not. A single point estimate
with its uncertainty cannot convey all the information that has been
drawn from the data. On the other hand, inflicting probability density
functions on decision makers is probably not wiser. Instead, we have
quite successfully used this pdf to answer typical questions raised
by users, such as ``What are the most likely energy savings?'',
``What energy savings can I expect on average?'', or ``How likely
am I to achieve energy savings of at least 20\%?''. All these questions
can be answered with the probability distribution function.

The following caveats should, however, be kept in mind:
\begin{itemize}
\item We have taken the reduction of the heat loss coefficient $K$ as being
synonymous with energy savings; this is only correct for a constant
base temperature. In particular, shifts in the indoor temperature
set point may either mitigate or magnify those energy savings.
\item We have assumed that the building's base temperature and heat loss
coefficient have remained constant during 2011\textendash 2015.
\item We have assumed that a linear relationship holds between the oil consumption
and the average outdoor temperature post-installation, but Fig.~\ref{fig:Signature}
suggests a good deal of variance that must be attributed to other
factors than the outdoor temperature, perhaps the solar irradiance.
\item Fig.~\ref{fig:Signature} also suggests that the building's base
temperature may have shifted upwards after the installation of the
NOL\textsuperscript{a} system. This happens when the temperature
set point programmed on the NOL\textsuperscript{a} is higher than
the average temperature kept by the original heating system. But historic
indoor temperatures are rarely available, and the NOL\textsuperscript{a}
installer relied on the temperature set point programmed on the original
heating system\textemdash which can be very different from the temperature
really desired by the user. This does not invalidate the above analysis,
but the building manager should consider adjusting those set points
to fully reap the energy savings.
\end{itemize}

\section{Conclusion}

Upgrading the heating control system of the building in Sargans has
lowered the total heat loss coefficient of that building by $\Sexpr{p(savingsPercent)}\pm\Sexpr{p(savingsError)}$
\%. This estimate was obtained by fitting a probability model to the
pre- and post-retrofit oil consumption data. The parameters of that
model include the building's total heat loss coefficient and its base
temperature, both before and after the installation. This yielded
a probability density function in all the building's parameters, from
which the effect on the heat loss coefficient were estimated.

We have used a Bayesian analysis framework throughout this analysis
and compared it with a more classical counterpart (a non-linear regression
approach). Both approaches were able to:
\begin{itemize}
\item handle a complex probability model, such as the one relating the daily
energy consumption to the mean outdoor temperature
\item take into account data from very different sources (pre-retrofit manual
entries and post-retrofit automated daily readouts)
\item estimate the pre- and post-installation building model parameters
\end{itemize}
The Bayesian approach had the following advantages over its counterpart:
\begin{itemize}
\item the clear interpretability and communicability of its results
\item easier to program (we had to work around certain limitations in the
non-linear regression package provided by R)
\item less ad-hoc assumptions
\end{itemize}
Since this is a case study on a real building (with unknown ``real''
parameters) we cannot judge which method is the more accurate. But
because of its simplicity, ease of programming, and lack of arbitrary
assumptions, our preference goes to the Bayesian method, with which
we were able to avoid a costly pre-retrofit period of measurements.
The owner of the building was aware that the precision of the energy
savings was going to be limited by the accuracy of the pre-retrofit
manual readouts, but appreciated the efforts made to communicate them
in a way easy to understand for decision-makers.

Not all buildings will enjoy the luxury of automated energy consumption
readouts, and it is likely that future projects will have no choice
but to rely on manual readouts both before and after the retrofit.
The Bayesian framework will be able to handle these situations, but
with an interesting twist: it will probably be possible to pool the
pre- and post-retrofit data to better estimate the daily energy consumption
variability $\sigma$, which we did not do here because the data acquisition
methods were completely different.

Another vexing point concerns the apparent shift in the building's
base temperature. Some shift is probably inevitable due to a change
in the average indoor temperature, but can the entire shift be entirely
attributed to the indoor temperature alone? Or is there something
inherent in the new control system that also shifts that base temperature?
This too remains an interesting open question.

\section*{Acknowledgements}

We'd like to thank the following Swisscom employees for their help
and support in this project: Res Witschi (Leiter Corporate Responsibility),
Pascal Salina (Umweltmanagement Swisscom), and Stéphane Pralong (Owner's
Representative). We're also grateful to our colleague Stefanie Langenstein
for her meticulous review of early versions of this paper.

The inset map of Switzerland in Fig.~\ref{fig:stations} is the ``Switzerland
- Single Color'' vector map by FreeVectorMaps.com.

\section*{Appendix}

A photograph of the original, manual oil level readouts is shown in
Fig.~\ref{fig:readouts}.

\begin{figure*}
\begin{centering}
\includegraphics[width=90mm]{img/oil}
\par\end{centering}
\caption{The original manual oil level readouts}
\label{fig:readouts}
\end{figure*}

\noindent\fbox{\begin{minipage}[t]{1\columnwidth - 2\fboxsep - 2\fboxrule}%
\settowidth{\nomlabelwidth}{$\mathcal{N}(0,\sigma^{2})$}
\printnomenclature{}%
\end{minipage}}

\section*{References}

\bibliographystyle{elsarticle-patch}
\addcontentsline{toc}{section}{\refname}\bibliography{bibliography}

\end{document}
